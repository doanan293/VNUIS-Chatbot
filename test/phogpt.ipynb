{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T07:21:00.924166Z",
     "start_time": "2024-10-03T07:20:52.138403Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andv/.cache/huggingface/modules/transformers_modules/vinai/PhoGPT-4B-Chat/f56fc6d71f147a3a293fdab56676337dc6f641e1/configuration_mpt.py:114: UserWarning: alibi or rope is turned on, setting `learned_pos_emb` to `False.`\n",
      "  warnings.warn(f'alibi or rope is turned on, setting `learned_pos_emb` to `False.`')\n",
      "/home/andv/.cache/huggingface/modules/transformers_modules/vinai/PhoGPT-4B-Chat/f56fc6d71f147a3a293fdab56676337dc6f641e1/configuration_mpt.py:141: UserWarning: If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".\n",
      "  warnings.warn(UserWarning('If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".'))\n",
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "MPTForCausalLM does not support Flash Attention 2.0 yet. Please request to add support where the model is hosted, on its model hub page: https://huggingface.co/vinai/PhoGPT-4B-Chat/discussions/new or in the Transformers GitHub repo: https://github.com/huggingface/transformers/issues/new",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m      5\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvinai/PhoGPT-4B-Chat\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# model_path = \"/home/andv/important/Chatbot/finetune_llm/phogpt-mergerd-with-config-1\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# model_path = \"/home/andv/important/Chatbot/finetune\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# config.init_device = \"cuda\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# config.attn_config['attn_impl']= 'flash' # If installed: this will use either Flash Attention V1 or V2 depending on what is installed\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;66;43;03m#  config=config, \u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43muse_flash_attention_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# model = AutoModelForCausalLM.from_pretrained(model_path, config = config, trust_remote_code=True).to(\"cuda\")\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# If your GPU does not support bfloat16:\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# model = AutoModelForCausalLM.from_pretrained(model_path, config=config, torch_dtype=torch.float16, trust_remote_code=True)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \n",
      "File \u001b[0;32m~/important/Chatbot/.venv/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:559\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mregister(config\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, model_class, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    558\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m add_generation_mixin_to_remote_model(model_class)\n\u001b[0;32m--> 559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n",
      "File \u001b[0;32m~/important/Chatbot/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:3880\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3877\u001b[0m     init_contexts\u001b[38;5;241m.\u001b[39mappend(init_empty_weights())\n\u001b[1;32m   3879\u001b[0m config \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(config)  \u001b[38;5;66;03m# We do not want to modify the config inplace in from_pretrained.\u001b[39;00m\n\u001b[0;32m-> 3880\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autoset_attn_implementation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_flash_attention_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_flash_attention_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\n\u001b[1;32m   3882\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m   3885\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[1;32m   3886\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(config, \u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n",
      "File \u001b[0;32m~/important/Chatbot/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:1572\u001b[0m, in \u001b[0;36mPreTrainedModel._autoset_attn_implementation\u001b[0;34m(cls, config, use_flash_attention_2, torch_dtype, device_map, check_device_map)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     config\u001b[38;5;241m.\u001b[39m_attn_implementation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflash_attention_2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39m_attn_implementation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflash_attention_2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1572\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_and_enable_flash_attn_2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhard_check_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_device_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_device_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m requested_attn_implementation \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdpa\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   1580\u001b[0m     \u001b[38;5;66;03m# use_flash_attention_2 takes priority over SDPA, hence SDPA treated in this elif.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_enable_sdpa(\n\u001b[1;32m   1582\u001b[0m         config,\n\u001b[1;32m   1583\u001b[0m         hard_check_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m requested_attn_implementation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1584\u001b[0m     )\n",
      "File \u001b[0;32m~/important/Chatbot/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:1688\u001b[0m, in \u001b[0;36mPreTrainedModel._check_and_enable_flash_attn_2\u001b[0;34m(cls, config, torch_dtype, device_map, check_device_map, hard_check_only)\u001b[0m\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03mChecks the availability of Flash Attention 2 and compatibility with the current model.\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03mIf all checks pass and `hard_check_only` is False, the method will set the config attribute `attn_implementation` to \"flash_attention_2\" so that the model can initialize the correct attention module.\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_supports_flash_attn_2:\n\u001b[0;32m-> 1688\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1689\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not support Flash Attention 2.0 yet. Please request to add support where\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1690\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m the model is hosted, on its model hub page: https://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/discussions/new\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1691\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or in the Transformers GitHub repo: https://github.com/huggingface/transformers/issues/new\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1692\u001b[0m     )\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_flash_attn_2_available():\n\u001b[1;32m   1695\u001b[0m     preface \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlashAttention2 has been toggled on, but it cannot be used due to the following error:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: MPTForCausalLM does not support Flash Attention 2.0 yet. Please request to add support where the model is hosted, on its model hub page: https://huggingface.co/vinai/PhoGPT-4B-Chat/discussions/new or in the Transformers GitHub repo: https://github.com/huggingface/transformers/issues/new"
     ]
    }
   ],
   "source": [
    "# coding: utf8\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"vinai/PhoGPT-4B-Chat\"  \n",
    "# model_path = \"/home/andv/important/Chatbot/finetune_llm/phogpt-mergerd-with-config-1\"\n",
    "\n",
    "# model_path = \"/home/andv/important/Chatbot/finetune\"\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_path, trust_remote_code=True)  \n",
    "# config.init_device = \"cuda\"\n",
    "config.attn_config['attn_impl'] = 'flash' # If installed: this will use either Flash Attention V1 or V2 depending on what is installed\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "                                             config=config, \n",
    "                                             torch_dtype=torch.bfloat16, \n",
    "                                             trust_remote_code=True).to(\"cuda\")\n",
    "\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path, config = config, trust_remote_code=True).to(\"cuda\")\n",
    "# If your GPU does not support bfloat16:\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_path, config=config, torch_dtype=torch.float16, trust_remote_code=True)\n",
    "model.eval()  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)  \n",
    "\n",
    "PROMPT_TEMPLATE = \"### Câu hỏi: {instruction}\\n### Trả lời:\"  \n",
    "# PROMPT_TEMPLATE = \"{instruction}\"  \n",
    "# Some instruction examples\n",
    "# instruction = \"Viết bài văn nghị luận xã hội về {topic}\"\n",
    "# instruction = \"Viết bản mô tả công việc cho vị trí {job_title}\"\n",
    "# instruction = \"Sửa lỗi chính tả:\\n{sentence_or_paragraph}\"\n",
    "# instruction = \"Dựa vào văn bản sau đây:\\n{text}\\nHãy trả lời câu hỏi: {question}\"\n",
    "# instruction = \"Tóm tắt văn bản:\\n{text}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37cd0e6a6e220f83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T07:25:29.136824Z",
     "start_time": "2024-10-03T07:25:04.338478Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andv/.cache/huggingface/modules/transformers_modules/vinai/PhoGPT-4B-Chat/f56fc6d71f147a3a293fdab56676337dc6f641e1/configuration_mpt.py:141: UserWarning: If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".\n",
      "  warnings.warn(UserWarning('If not using a Prefix Language Model, we recommend setting \"attn_impl\" to \"flash\" instead of \"triton\".'))\n"
     ]
    }
   ],
   "source": [
    "instruction = \"Phần mềm quản lý ngân sách và tài chính xã Tuân thủ các quy định nào do Bộ Tài chính ban hành? \"\n",
    "# instruction = \"Sửa lỗi chính tả:\\nTriệt phá băng nhóm kướp ô tô, sử dụng \\\"vũ khí nóng\\\"\"\n",
    "\n",
    "input_prompt = PROMPT_TEMPLATE.format_map({\"instruction\": instruction})  \n",
    "\n",
    "input_ids = tokenizer(input_prompt, return_tensors=\"pt\")  \n",
    "\n",
    "outputs = model.generate(  \n",
    "    inputs=input_ids[\"input_ids\"].to(\"cuda\"),  \n",
    "    attention_mask=input_ids[\"attention_mask\"].to(\"cuda\"),  \n",
    "    do_sample=True,  \n",
    "    temperature=1.0,  \n",
    "    top_k=50,  \n",
    "    top_p=0.9,  \n",
    "    max_new_tokens=1024,  \n",
    "    eos_token_id=tokenizer.eos_token_id,  \n",
    "    pad_token_id=tokenizer.pad_token_id  \n",
    ")  \n",
    "\n",
    "response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  \n",
    "# response = tokenizer.decode(outputs[0])\n",
    "response = response.split(\"### Trả lời:\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0597c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theo Điều 8 Thông tư 19/2020/TT-BTC thì phần mềm quản lý ngân sách và tài chính xã đáp ứng các yêu cầu sau đây:\n",
      "\n",
      "1. Thực hiện các chức năng quy định tại điểm c khoản 2 Điều 3 Thông tư 19/2020/TT-BTC, trong đó có chức năng nhập dự toán thu, chi ngân sách xã (ngân sách xã không có tài khoản dự toán tại Kho bạc Nhà nước), nhập tình hình thực hiện dự toán thu, chi ngân sách xã.\n",
      "\n",
      "2. Hỗ trợ thực hiện phân bổ dự toán ngân sách xã cho các đơn vị sử dụng ngân sách trực thuộc (các xã); đồng thời, gửi Ủy ban nhân dân cấp huyện để theo dõi, quản lý theo quy định.\n",
      "\n",
      "3. Hỗ trợ thực hiện tổng hợp báo cáo thu, chi ngân sách xã (bao gồm cả báo cáo thuyết minh, giải trình kết quả thu và chi ngân sách xã) theo mẫu biểu báo cáo tài chính quy định, gửi Ủy ban nhân dân cấp huyện và cơ quan tài chính cấp huyện.\n",
      "\n",
      "4. Hỗ trợ thực hiện đối chiếu, xác nhận số liệu thu, chi ngân sách xã với Kho bạc Nhà nước cấp huyện.\n",
      "\n",
      "5. Hỗ trợ công khai thông tin ngân sách xã và các hoạt động tài chính khác của xã theo quy định của pháp luật.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc4d74026655fcac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T07:25:29.145340Z",
     "start_time": "2024-10-03T07:25:29.142993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phần mềm kế toán hành chính là một công cụ phần mềm được sử dụng để quản lý tài chính của tổ chức, doanh nghiệp hoặc cơ quan nhà nước. Phần mềm này cho phép người sử dụng nhập các chi tiết liên quan đến tài chính của tổ chức, bao gồm các giao dịch tài chính như bán hàng, thu chi, tiền lương và tài sản cố định. Phần mềm kế toán hành chính giúp cho người dùng quản lý các hoạt động tài chính của tổ chức một cách nhanh chóng và hiệu quả, giảm thiểu các sai sót và nhầm lẫn trong việc theo dõi và tính toán tài chính. Ngoài ra, phần mềm này cũng giúp tăng cường tính chính xác của các hoạt động tài chính của tổ chức, giúp cho việc quản lý và điều hành tổ chức một cách dễ dàng hơn.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "578fc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": \"Kể tên một môn thể thao mạo hiểm\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"Nhảy Bungee.\"},\n",
    "#     {\"role\": \"user\", \"content\": \"Bạn đã bao giờ đi nhảy bungee chưa\"}\n",
    "# ]\n",
    "\n",
    "# # Using apply_chat_template\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"vinai/PhoGPT-4B-Chat\", trust_remote_code=True)\n",
    "# input_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3968518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Câu hỏi: Kể tên một môn thể thao mạo hiểm\\n### Trả lời: Nhảy Bungee.</s>\\n### Câu hỏi: Bạn đã bao giờ đi nhảy bungee chưa\\n### Trả lời:'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cecefeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids = tokenizer(input_prompt, return_tensors=\"pt\")  \n",
    "\n",
    "# outputs = model.generate(  \n",
    "#     inputs=input_ids[\"input_ids\"].to(\"cuda\"),  \n",
    "#     attention_mask=input_ids[\"attention_mask\"].to(\"cuda\"),  \n",
    "#     do_sample=True,  \n",
    "#     temperature=1.0,  \n",
    "#     top_k=50,  \n",
    "#     top_p=0.9,  \n",
    "#     max_new_tokens=1024,  \n",
    "#     eos_token_id=tokenizer.eos_token_id,  \n",
    "#     pad_token_id=tokenizer.pad_token_id  \n",
    "# )  \n",
    "\n",
    "# response = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  \n",
    "# # response = tokenizer.decode(outputs[0])\n",
    "# # response = response.split(\"### Trả lời:\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e74c84c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Câu hỏi: Kể tên một môn thể thao mạo hiểm\\n### Trả lời: Nhảy Bungee.\\n### Câu hỏi: Bạn đã bao giờ đi nhảy bungee chưa\\n### Trả lời: Là một mô hình ngôn ngữ AI, tôi không có khả năng tham gia vào các hoạt động thể chất, nên tôi không có kinh nghiệm nhảy bungee.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1130ff35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Câu hỏi: Kể tên một môn thể thao mạo hiểm\\n### Trả lời: Nhảy Bungee.</s>\\n### Câu hỏi: Bạn đã bao giờ đi nhảy bungee chưa\\n### Trả lời:'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1c0a9b222a17a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T04:59:08.923171Z",
     "start_time": "2024-09-28T04:59:08.917427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Món ăn ngon nhất ở Hà Nội\\nĂn gì ở Hà Nội là câu hỏi được đặt ra cho rất nhiều du khách. Bởi Hà Nội là một trong những địa danh nổi tiếng với nhiều món ăn hấp dẫn. Hà Nội được coi là một thiên đường ẩm thực với rất nhiều món ăn ngon, độc đáo. Vậy ăn gì ở Hà Nội?\\nBài viết dưới đây sẽ giới thiệu cho bạn top 10 món ăn ngon nhất ở Hà Nội.\\nTop 10 món ăn ngon nhất ở Hà Nội\\n1. Phở Hà Nội - Một trong những món ăn ngon nhất ở Hà Nội\\nPhở là món ăn ngon và nổi tiếng nhất ở Hà Nội. Phở là món ăn truyền thống, được yêu thích từ lâu đời của người dân thủ đô. Phở Hà Nội có hương vị đậm đà, nước dùng thơm ngon, bánh phở mềm dai, kết hợp với các loại gia vị, thảo mộc như hành lá, rau thơm, nước mắm, nước cốt chanh, ớt, hạt tiêu... Phở Hà Nội thường được phục vụ trong các quán phở truyền thống và nổi tiếng nhất là Phở Bát Đàn, Phở Thìn, Phở Lý Quốc Sư.\\n2. Bún chả Hà Nội - Một trong những món ăn ngon nhất ở Hà Nội\\nBún chả là món ăn ngon và nổi tiếng của Việt Nam. Bún chả Hà Nội được làm từ thịt lợn nướng, chả băm, bún tươi và nước mắm. Bún chả Hà Nội có hương vị đậm đà, thơm ngon, có thể ăn kèm với các loại rau thơm, rau sống.\\n3. Chả cá Hà Nội - Một trong những món ăn ngon nhất ở Hà Nội\\nChả cá Hà Nội là món ăn ngon, hấp dẫn và độc đáo. Chả cá Hà Nội được làm từ cá lăng hoặc cá lóc, có hương vị đậm đà, thơm ngon, được phục vụ kèm với các loại rau thơm, nước mắm và bún tươi.\\n4. Bánh cuốn Hà Nội - Một trong những món ăn ngon nhất ở Hà Nội\\nBánh cuốn Hà Nội là món ăn được làm từ bột gạo, có hương vị thơm ngon, ngọt thanh. Bánh cuốn Hà Nội thường được phục vụ kèm với chả lụa, nem nướng và nước mắm.\\n5. Nem rán Hà Nội - Một trong những món ăn ngon nhất ở Hà Nội\\nNem rán Hà Nội là món ăn ngon, độc đáo và phổ biến. Nem rán Hà Nội được làm từ thịt lợn xay, miến, nấm mèo, củ sắn, trứng, rau thơm, gia vị. Nem rán Hà Nội có hương vị thơm ngon, dai dai, giòn giòn.\\n6. Bánh mì Hà Nội - Một trong những món ăn ngon nhất ở Hà Nội\\nBánh mì Hà Nội là món ăn được yêu thích từ lâu đời. Bánh mì Hà Nội được làm từ bột mì, có hương vị thơm ngon, ngọt thanh, thường được phục vụ kèm với các loại rau thơm, nước sốt.\\n7. Chả cá Lã Vọng Hà Nội - Một trong những món ăn ngon nhất ở Hà Nội\\nChả cá Lã Vọng Hà Nội là món ăn ngon và nổi tiếng. Chả cá Lã Vọng Hà Nội được làm từ cá lăng hoặc cá lóc, có hương vị đậm đà, thơm ngon, được phục vụ kèm với các loại rau thơm, nước mắm và bún tươi.\\n8. Bún thang Hà Nội - Một trong những món ăn ngon nhất ở Hà Nội\\nBún thang Hà Nội là món ăn ngon và độc đáo. Bún thang Hà Nội được làm từ trứng gà, gà xé nhỏ, nấm hương, củ cải, hành lá, gia vị. Bún thang Hà Nội có hương vị thơm ngon, ngọt thanh, thường được phục vụ kèm với các loại rau thơm, nước mắm.\\n9. Bánh cuốn Thanh Trì Hà Nội - Một trong những món ăn ngon nhất ở Hà Nội\\nBánh cuốn Thanh Trì Hà Nội là món ăn được làm từ bột gạo, có hương vị thơm ngon, ngọt thanh. Bánh cuốn Thanh Trì Hà Nội được phục vụ kèm với các loại rau thơm, nước mắm.\\n10. Chè Hà Nội - Một trong những món ăn ngon nhất ở Hà Nội\\nChè Hà Nội là món ăn được yêu thích từ lâu đời. Chè Hà Nội được làm từ các loại đậu, đỗ, hạt sen, khoai môn, thạch, trân châu và nước cốt dừa. Chè Hà Nội có hương vị ngọt thanh, thơm ngon, thường được phục vụ kèm với các loại đậu, thạch và nước cốt dừa.</s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1128fa83d7885fcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T04:56:07.460562Z",
     "start_time": "2024-09-28T04:56:07.458005Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Món ăn ngon nhất ở Hà Nội\\nKhông chỉ nổi tiếng với những danh lam thắng cảnh đẹp, những món ăn ngon cũng là một điểm nhấn khiến Hà Nội luôn là lựa chọn hàng đầu của du khách trong và ngoài nước.\\nMột số món ăn ngon không thể không nhắc đến khi đến Hà Nội:\\n- Phở: Đây là món ăn truyền thống được rất nhiều người yêu thích. Phở có thể ăn sáng, trưa, chiều tối đều ngon. Đặc biệt, đến Hà Nội vào mùa đông mà không thưởng thức phở thì thật là đáng tiếc.\\n- Bún chả: Đây là món ăn nổi tiếng của Hà Nội và cũng là món ăn ngon được nhiều người nước ngoài biết đến. Bún chả được bán tại các quán ăn ven đường, bạn có thể ghé vào để thưởng thức.\\n- Chả cá Lã Vọng: Đây là món ăn ngon được chế biến từ cá lăng, được làm thành chả cá, đem nướng và ăn kèm với bún và các loại rau thơm.\\n- Bánh tôm: Đây là món ăn ngon đặc trưng của Hà Nội, được bán nhiều tại các nhà hàng, quán ăn ven đường. Bạn có thể đến các địa điểm như: đường Lý Quốc Sư, Thanh Niên để thưởng thức món ăn ngon này.\\n- Chả rươi: Nếu muốn thưởng thức món ăn đặc biệt này, bạn có thể đến phố cổ vào mùa rươi để thưởng thức.\\n- Nem cuốn: Đây là món ăn ngon, được làm từ bánh đa cuốn với các loại rau, thịt, giò, chấm với nước mắm chua ngọt.\\n- Bánh cuốn: Đây là món ăn truyền thống của Hà Nội, thường được bán vào buổi sáng, rất thích hợp cho những người muốn thưởng thức bữa sáng ngon.\\n- Chè: Ở Hà Nội có rất nhiều loại chè ngon, được bán tại các quán ăn vặt hoặc những địa điểm quen thuộc.\\n- Bánh mì: Đến Hà Nội mà không thưởng thức bánh mì thì quả thật là đáng tiếc. Các loại bánh mì được yêu thích như: Bánh mì trứng, bánh mì pate, bánh mì thịt nguội...\\nTrên đây là một số món ăn ngon đặc trưng của Hà Nội mà bạn nên thưởng thức. Mỗi món ăn đều mang một nét độc đáo riêng, tạo nên bản sắc ẩm thực của Hà Nội.\\nHy vọng những thông tin này sẽ giúp bạn có một chuyến du lịch Hà Nội đáng nhớ và thưởng thức được những món ăn ngon nhất ở nơi đây.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
