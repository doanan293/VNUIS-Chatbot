{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/admin-hieunn/important/VNUIS-Chatbot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-hieunn/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "cd .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin-hieunn/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_768_cosine_accuracy@1 0.6781059947871416\n",
      "dim_768_cosine_accuracy@3 0.8783666377063423\n",
      "dim_768_cosine_accuracy@5 0.9135534317984362\n",
      "dim_768_cosine_accuracy@10 0.94874022589053\n",
      "dim_768_cosine_precision@1 0.6781059947871416\n",
      "dim_768_cosine_precision@3 0.29278887923544744\n",
      "dim_768_cosine_precision@5 0.18271068635968718\n",
      "dim_768_cosine_precision@10 0.09487402258905299\n",
      "dim_768_cosine_recall@1 0.6781059947871416\n",
      "dim_768_cosine_recall@3 0.8783666377063423\n",
      "dim_768_cosine_recall@5 0.9135534317984362\n",
      "dim_768_cosine_recall@10 0.94874022589053\n",
      "dim_768_cosine_ndcg@10 0.8248530495073324\n",
      "dim_768_cosine_mrr@10 0.7839509812033691\n",
      "dim_768_cosine_map@100 0.7867942877699591\n",
      "dim_512_cosine_accuracy@1 0.6772371850564727\n",
      "dim_512_cosine_accuracy@3 0.8718505647263249\n",
      "dim_512_cosine_accuracy@5 0.9122502172024327\n",
      "dim_512_cosine_accuracy@10 0.9539530842745438\n",
      "dim_512_cosine_precision@1 0.6772371850564727\n",
      "dim_512_cosine_precision@3 0.290616854908775\n",
      "dim_512_cosine_precision@5 0.18245004344048651\n",
      "dim_512_cosine_precision@10 0.09539530842745438\n",
      "dim_512_cosine_recall@1 0.6772371850564727\n",
      "dim_512_cosine_recall@3 0.8718505647263249\n",
      "dim_512_cosine_recall@5 0.9122502172024327\n",
      "dim_512_cosine_recall@10 0.9539530842745438\n",
      "dim_512_cosine_ndcg@10 0.8252202162115325\n",
      "dim_512_cosine_mrr@10 0.7830399376663485\n",
      "dim_512_cosine_map@100 0.7855850792582005\n",
      "dim_256_cosine_accuracy@1 0.6607298001737619\n",
      "dim_256_cosine_accuracy@3 0.8601216333622936\n",
      "dim_256_cosine_accuracy@5 0.9092093831450913\n",
      "dim_256_cosine_accuracy@10 0.9556907037358818\n",
      "dim_256_cosine_precision@1 0.6607298001737619\n",
      "dim_256_cosine_precision@3 0.2867072111207645\n",
      "dim_256_cosine_precision@5 0.18184187662901824\n",
      "dim_256_cosine_precision@10 0.09556907037358817\n",
      "dim_256_cosine_recall@1 0.6607298001737619\n",
      "dim_256_cosine_recall@3 0.8601216333622936\n",
      "dim_256_cosine_recall@5 0.9092093831450913\n",
      "dim_256_cosine_recall@10 0.9556907037358818\n",
      "dim_256_cosine_ndcg@10 0.8155609361158851\n",
      "dim_256_cosine_mrr@10 0.7698714368458061\n",
      "dim_256_cosine_map@100 0.772288471399729\n",
      "dim_128_cosine_accuracy@1 0.6350999131190269\n",
      "dim_128_cosine_accuracy@3 0.8440486533449174\n",
      "dim_128_cosine_accuracy@5 0.8979148566463945\n",
      "dim_128_cosine_accuracy@10 0.9539530842745438\n",
      "dim_128_cosine_precision@1 0.6350999131190269\n",
      "dim_128_cosine_precision@3 0.28134955111497245\n",
      "dim_128_cosine_precision@5 0.1795829713292789\n",
      "dim_128_cosine_precision@10 0.09539530842745438\n",
      "dim_128_cosine_recall@1 0.6350999131190269\n",
      "dim_128_cosine_recall@3 0.8440486533449174\n",
      "dim_128_cosine_recall@5 0.8979148566463945\n",
      "dim_128_cosine_recall@10 0.9539530842745438\n",
      "dim_128_cosine_ndcg@10 0.8005613627332834\n",
      "dim_128_cosine_mrr@10 0.7508041661495166\n",
      "dim_128_cosine_map@100 0.7533194907110878\n",
      "dim_64_cosine_accuracy@1 0.5682015638575152\n",
      "dim_64_cosine_accuracy@3 0.7962641181581234\n",
      "dim_64_cosine_accuracy@5 0.8579496090356212\n",
      "dim_64_cosine_accuracy@10 0.9378801042571677\n",
      "dim_64_cosine_precision@1 0.5682015638575152\n",
      "dim_64_cosine_precision@3 0.2654213727193744\n",
      "dim_64_cosine_precision@5 0.17158992180712423\n",
      "dim_64_cosine_precision@10 0.09378801042571676\n",
      "dim_64_cosine_recall@1 0.5682015638575152\n",
      "dim_64_cosine_recall@3 0.7962641181581234\n",
      "dim_64_cosine_recall@5 0.8579496090356212\n",
      "dim_64_cosine_recall@10 0.9378801042571677\n",
      "dim_64_cosine_ndcg@10 0.7549798404199489\n",
      "dim_64_cosine_mrr@10 0.6962732544509247\n",
      "dim_64_cosine_map@100 0.6995867365038122\n",
      "sequential_score 0.6995867365038122\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from sentence_transformers.losses import MatryoshkaLoss, MultipleNegativesRankingLoss\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.evaluation import (\n",
    "    InformationRetrievalEvaluator,\n",
    "    SequentialEvaluator,\n",
    ")\n",
    "from sentence_transformers.util import cos_sim\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from sentence_transformers import SentenceTransformerTrainingArguments\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers import SentenceTransformerTrainer\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "corpus = pd.read_csv(\"./Data/finetune_embedding/corpus.csv\")\n",
    "queries = pd.read_csv(\"./Data/finetune_embedding/queries.csv\")\n",
    "relevant_docs_data = pd.read_csv(\"./Data/finetune_embedding/eval.csv\")\n",
    "\n",
    "\n",
    "corpus = Dataset.from_pandas(corpus)\n",
    "queries = Dataset.from_pandas(queries)\n",
    "relevant_docs_data = Dataset.from_pandas(relevant_docs_data)\n",
    "# Convert the datasets to dictionaries\n",
    "corpus = dict(\n",
    "    zip(corpus[\"relevantdocs_id\"], corpus[\"Relevant docs\"])\n",
    ")  # Our corpus (cid => document)\n",
    "queries = dict(\n",
    "    zip(queries[\"queries_id\"], queries[\"Question\"])\n",
    ")  # Our queries (qid => question)\n",
    "# Convert integer keys to string keys\n",
    "queries = {str(key): value for key, value in queries.items()}\n",
    "# Now your 'queries' dictionary will have string keys\n",
    "\n",
    "relevant_docs = {}  # Query ID to relevant documents (qid => set([relevant_cids])\n",
    "for qid, corpus_ids in zip(\n",
    "    relevant_docs_data[\"queries_id\"], relevant_docs_data[\"relevantdocs_id\"]\n",
    "):\n",
    "    qid = str(qid)\n",
    "    corpus_ids = str(corpus_ids)\n",
    "    if qid not in relevant_docs:\n",
    "        relevant_docs[qid] = set()\n",
    "    relevant_docs[qid].add(corpus_ids)\n",
    "\n",
    "model = SentenceTransformer(\n",
    "    # model_name_or_path=\"BAAI/bge-m3\",\n",
    "    model_name_or_path=\"/home/admin-hieunn/important/VNUIS-Chatbot/Model/vnuis_embedding_bge_20241227\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64]  # Important: large to small\n",
    "matryoshka_evaluators = []\n",
    "# Iterate over the different dimensions\n",
    "for dim in matryoshka_dimensions:\n",
    "    ir_evaluator = InformationRetrievalEvaluator(\n",
    "        queries=queries,\n",
    "        corpus=corpus,\n",
    "        relevant_docs=relevant_docs,\n",
    "        name=f\"dim_{dim}\",\n",
    "        truncate_dim=dim,  # Truncate the embeddings to a certain dimension\n",
    "        score_functions={\"cosine\": cos_sim},\n",
    "    )\n",
    "    matryoshka_evaluators.append(ir_evaluator)\n",
    "\n",
    "# Create a sequential evaluator\n",
    "evaluator = SequentialEvaluator(matryoshka_evaluators)\n",
    "\n",
    "# Evaluate the model and ensure it's all on the correct device\n",
    "results = evaluator(model)\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-27 16:31:24,205] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "  8%|▊         | 10/120 [05:42<1:01:10, 33.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6823, 'grad_norm': 17.194053649902344, 'learning_rate': 1.6666666666666667e-05, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10/120 [06:24<1:01:10, 33.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.7072111207645526, 'eval_dim_768_cosine_accuracy@3': 0.8801042571676803, 'eval_dim_768_cosine_accuracy@5': 0.9139878366637706, 'eval_dim_768_cosine_accuracy@10': 0.946133796698523, 'eval_dim_768_cosine_precision@1': 0.7072111207645526, 'eval_dim_768_cosine_precision@3': 0.29336808572256007, 'eval_dim_768_cosine_precision@5': 0.1827975673327541, 'eval_dim_768_cosine_precision@10': 0.09461337966985228, 'eval_dim_768_cosine_recall@1': 0.7072111207645526, 'eval_dim_768_cosine_recall@3': 0.8801042571676803, 'eval_dim_768_cosine_recall@5': 0.9139878366637706, 'eval_dim_768_cosine_recall@10': 0.946133796698523, 'eval_dim_768_cosine_ndcg@10': 0.8356623746856879, 'eval_dim_768_cosine_mrr@10': 0.7993144332740328, 'eval_dim_768_cosine_map@100': 0.8013748706823961, 'eval_dim_512_cosine_accuracy@1': 0.6980886185925282, 'eval_dim_512_cosine_accuracy@3': 0.8748913987836664, 'eval_dim_512_cosine_accuracy@5': 0.9152910512597741, 'eval_dim_512_cosine_accuracy@10': 0.944396177237185, 'eval_dim_512_cosine_precision@1': 0.6980886185925282, 'eval_dim_512_cosine_precision@3': 0.2916304662612221, 'eval_dim_512_cosine_precision@5': 0.18305821025195482, 'eval_dim_512_cosine_precision@10': 0.09443961772371849, 'eval_dim_512_cosine_recall@1': 0.6980886185925282, 'eval_dim_512_cosine_recall@3': 0.8748913987836664, 'eval_dim_512_cosine_recall@5': 0.9152910512597741, 'eval_dim_512_cosine_recall@10': 0.944396177237185, 'eval_dim_512_cosine_ndcg@10': 0.8302591193185361, 'eval_dim_512_cosine_mrr@10': 0.7926840704425407, 'eval_dim_512_cosine_map@100': 0.79495485767554, 'eval_dim_256_cosine_accuracy@1': 0.6772371850564727, 'eval_dim_256_cosine_accuracy@3': 0.8609904430929627, 'eval_dim_256_cosine_accuracy@5': 0.9035621198957429, 'eval_dim_256_cosine_accuracy@10': 0.9396177237185056, 'eval_dim_256_cosine_precision@1': 0.6772371850564727, 'eval_dim_256_cosine_precision@3': 0.28699681436432084, 'eval_dim_256_cosine_precision@5': 0.18071242397914858, 'eval_dim_256_cosine_precision@10': 0.09396177237185055, 'eval_dim_256_cosine_recall@1': 0.6772371850564727, 'eval_dim_256_cosine_recall@3': 0.8609904430929627, 'eval_dim_256_cosine_recall@5': 0.9035621198957429, 'eval_dim_256_cosine_recall@10': 0.9396177237185056, 'eval_dim_256_cosine_ndcg@10': 0.8168725985543531, 'eval_dim_256_cosine_mrr@10': 0.776635051645911, 'eval_dim_256_cosine_map@100': 0.7789549103652382, 'eval_dim_128_cosine_accuracy@1': 0.6346655082536924, 'eval_dim_128_cosine_accuracy@3': 0.8175499565595135, 'eval_dim_128_cosine_accuracy@5': 0.8688097306689835, 'eval_dim_128_cosine_accuracy@10': 0.9157254561251086, 'eval_dim_128_cosine_precision@1': 0.6346655082536924, 'eval_dim_128_cosine_precision@3': 0.27251665218650445, 'eval_dim_128_cosine_precision@5': 0.1737619461337967, 'eval_dim_128_cosine_precision@10': 0.09157254561251085, 'eval_dim_128_cosine_recall@1': 0.6346655082536924, 'eval_dim_128_cosine_recall@3': 0.8175499565595135, 'eval_dim_128_cosine_recall@5': 0.8688097306689835, 'eval_dim_128_cosine_recall@10': 0.9157254561251086, 'eval_dim_128_cosine_ndcg@10': 0.7805586389591574, 'eval_dim_128_cosine_mrr@10': 0.7366413608594319, 'eval_dim_128_cosine_map@100': 0.7400697629726173, 'eval_dim_64_cosine_accuracy@1': 0.5125977410947002, 'eval_dim_64_cosine_accuracy@3': 0.7293657688966116, 'eval_dim_64_cosine_accuracy@5': 0.7997393570807994, 'eval_dim_64_cosine_accuracy@10': 0.86750651607298, 'eval_dim_64_cosine_precision@1': 0.5125977410947002, 'eval_dim_64_cosine_precision@3': 0.2431219229655372, 'eval_dim_64_cosine_precision@5': 0.15994787141615982, 'eval_dim_64_cosine_precision@10': 0.086750651607298, 'eval_dim_64_cosine_recall@1': 0.5125977410947002, 'eval_dim_64_cosine_recall@3': 0.7293657688966116, 'eval_dim_64_cosine_recall@5': 0.7997393570807994, 'eval_dim_64_cosine_recall@10': 0.86750651607298, 'eval_dim_64_cosine_ndcg@10': 0.6919032721370283, 'eval_dim_64_cosine_mrr@10': 0.6354164080923418, 'eval_dim_64_cosine_map@100': 0.6407845533827057, 'eval_sequential_score': 0.6407845533827057, 'eval_runtime': 42.0257, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 20/120 [12:11<58:11, 34.91s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2366, 'grad_norm': 15.337178230285645, 'learning_rate': 1.973044870579824e-05, 'epoch': 4.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 20/120 [12:54<58:11, 34.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6776715899218071, 'eval_dim_768_cosine_accuracy@3': 0.8801042571676803, 'eval_dim_768_cosine_accuracy@5': 0.9135534317984362, 'eval_dim_768_cosine_accuracy@10': 0.947871416159861, 'eval_dim_768_cosine_precision@1': 0.6776715899218071, 'eval_dim_768_cosine_precision@3': 0.29336808572256007, 'eval_dim_768_cosine_precision@5': 0.18271068635968718, 'eval_dim_768_cosine_precision@10': 0.09478714161598609, 'eval_dim_768_cosine_recall@1': 0.6776715899218071, 'eval_dim_768_cosine_recall@3': 0.8801042571676803, 'eval_dim_768_cosine_recall@5': 0.9135534317984362, 'eval_dim_768_cosine_recall@10': 0.947871416159861, 'eval_dim_768_cosine_ndcg@10': 0.824799747363737, 'eval_dim_768_cosine_mrr@10': 0.7840940589963166, 'eval_dim_768_cosine_map@100': 0.787013899142166, 'eval_dim_512_cosine_accuracy@1': 0.6776715899218071, 'eval_dim_512_cosine_accuracy@3': 0.8714161598609904, 'eval_dim_512_cosine_accuracy@5': 0.9122502172024327, 'eval_dim_512_cosine_accuracy@10': 0.9543874891398784, 'eval_dim_512_cosine_precision@1': 0.6776715899218071, 'eval_dim_512_cosine_precision@3': 0.2904720532869968, 'eval_dim_512_cosine_precision@5': 0.18245004344048651, 'eval_dim_512_cosine_precision@10': 0.09543874891398783, 'eval_dim_512_cosine_recall@1': 0.6776715899218071, 'eval_dim_512_cosine_recall@3': 0.8714161598609904, 'eval_dim_512_cosine_recall@5': 0.9122502172024327, 'eval_dim_512_cosine_recall@10': 0.9543874891398784, 'eval_dim_512_cosine_ndcg@10': 0.8252562146701834, 'eval_dim_512_cosine_mrr@10': 0.7829837408464678, 'eval_dim_512_cosine_map@100': 0.7854982896738093, 'eval_dim_256_cosine_accuracy@1': 0.661598609904431, 'eval_dim_256_cosine_accuracy@3': 0.8592528236316247, 'eval_dim_256_cosine_accuracy@5': 0.9083405734144222, 'eval_dim_256_cosine_accuracy@10': 0.9548218940052129, 'eval_dim_256_cosine_precision@1': 0.661598609904431, 'eval_dim_256_cosine_precision@3': 0.2864176078772082, 'eval_dim_256_cosine_precision@5': 0.1816681146828844, 'eval_dim_256_cosine_precision@10': 0.09548218940052126, 'eval_dim_256_cosine_recall@1': 0.661598609904431, 'eval_dim_256_cosine_recall@3': 0.8592528236316247, 'eval_dim_256_cosine_recall@5': 0.9083405734144222, 'eval_dim_256_cosine_recall@10': 0.9548218940052129, 'eval_dim_256_cosine_ndcg@10': 0.8156355784936558, 'eval_dim_256_cosine_mrr@10': 0.7702360266434974, 'eval_dim_256_cosine_map@100': 0.7727346032654664, 'eval_dim_128_cosine_accuracy@1': 0.634231103388358, 'eval_dim_128_cosine_accuracy@3': 0.845351867940921, 'eval_dim_128_cosine_accuracy@5': 0.8979148566463945, 'eval_dim_128_cosine_accuracy@10': 0.9543874891398784, 'eval_dim_128_cosine_precision@1': 0.634231103388358, 'eval_dim_128_cosine_precision@3': 0.281783955980307, 'eval_dim_128_cosine_precision@5': 0.1795829713292789, 'eval_dim_128_cosine_precision@10': 0.09543874891398783, 'eval_dim_128_cosine_recall@1': 0.634231103388358, 'eval_dim_128_cosine_recall@3': 0.845351867940921, 'eval_dim_128_cosine_recall@5': 0.8979148566463945, 'eval_dim_128_cosine_recall@10': 0.9543874891398784, 'eval_dim_128_cosine_ndcg@10': 0.8002230437828618, 'eval_dim_128_cosine_mrr@10': 0.7502325445092587, 'eval_dim_128_cosine_map@100': 0.7527209493476971, 'eval_dim_64_cosine_accuracy@1': 0.5690703735881842, 'eval_dim_64_cosine_accuracy@3': 0.7953953084274544, 'eval_dim_64_cosine_accuracy@5': 0.8592528236316247, 'eval_dim_64_cosine_accuracy@10': 0.9352736750651607, 'eval_dim_64_cosine_precision@1': 0.5690703735881842, 'eval_dim_64_cosine_precision@3': 0.26513176947581807, 'eval_dim_64_cosine_precision@5': 0.17185056472632493, 'eval_dim_64_cosine_precision@10': 0.09352736750651605, 'eval_dim_64_cosine_recall@1': 0.5690703735881842, 'eval_dim_64_cosine_recall@3': 0.7953953084274544, 'eval_dim_64_cosine_recall@5': 0.8592528236316247, 'eval_dim_64_cosine_recall@10': 0.9352736750651607, 'eval_dim_64_cosine_ndcg@10': 0.7545931264224619, 'eval_dim_64_cosine_mrr@10': 0.6964920083295395, 'eval_dim_64_cosine_map@100': 0.7000602061691158, 'eval_sequential_score': 0.7000602061691158, 'eval_runtime': 42.1411, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 4.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 30/120 [18:41<53:13, 35.48s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5207, 'grad_norm': 6.894130706787109, 'learning_rate': 1.866025403784439e-05, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 30/120 [19:23<53:13, 35.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6733275412684622, 'eval_dim_768_cosine_accuracy@3': 0.8609904430929627, 'eval_dim_768_cosine_accuracy@5': 0.9083405734144222, 'eval_dim_768_cosine_accuracy@10': 0.9496090356211989, 'eval_dim_768_cosine_precision@1': 0.6733275412684622, 'eval_dim_768_cosine_precision@3': 0.28699681436432084, 'eval_dim_768_cosine_precision@5': 0.1816681146828844, 'eval_dim_768_cosine_precision@10': 0.09496090356211988, 'eval_dim_768_cosine_recall@1': 0.6733275412684622, 'eval_dim_768_cosine_recall@3': 0.8609904430929627, 'eval_dim_768_cosine_recall@5': 0.9083405734144222, 'eval_dim_768_cosine_recall@10': 0.9496090356211989, 'eval_dim_768_cosine_ndcg@10': 0.818589713052241, 'eval_dim_768_cosine_mrr@10': 0.7758020975549199, 'eval_dim_768_cosine_map@100': 0.779000657177445, 'eval_dim_512_cosine_accuracy@1': 0.6655082536924414, 'eval_dim_512_cosine_accuracy@3': 0.8605560382276282, 'eval_dim_512_cosine_accuracy@5': 0.9070373588184187, 'eval_dim_512_cosine_accuracy@10': 0.9535186794092094, 'eval_dim_512_cosine_precision@1': 0.6655082536924414, 'eval_dim_512_cosine_precision@3': 0.2868520127425427, 'eval_dim_512_cosine_precision@5': 0.18140747176368371, 'eval_dim_512_cosine_precision@10': 0.09535186794092095, 'eval_dim_512_cosine_recall@1': 0.6655082536924414, 'eval_dim_512_cosine_recall@3': 0.8605560382276282, 'eval_dim_512_cosine_recall@5': 0.9070373588184187, 'eval_dim_512_cosine_recall@10': 0.9535186794092094, 'eval_dim_512_cosine_ndcg@10': 0.8160636108714199, 'eval_dim_512_cosine_mrr@10': 0.7713453104960476, 'eval_dim_512_cosine_map@100': 0.7743535440069996, 'eval_dim_256_cosine_accuracy@1': 0.6416159860990444, 'eval_dim_256_cosine_accuracy@3': 0.8457862728062554, 'eval_dim_256_cosine_accuracy@5': 0.8970460469157254, 'eval_dim_256_cosine_accuracy@10': 0.9569939183318853, 'eval_dim_256_cosine_precision@1': 0.6416159860990444, 'eval_dim_256_cosine_precision@3': 0.28192875760208513, 'eval_dim_256_cosine_precision@5': 0.17940920938314509, 'eval_dim_256_cosine_precision@10': 0.09569939183318853, 'eval_dim_256_cosine_recall@1': 0.6416159860990444, 'eval_dim_256_cosine_recall@3': 0.8457862728062554, 'eval_dim_256_cosine_recall@5': 0.8970460469157254, 'eval_dim_256_cosine_recall@10': 0.9569939183318853, 'eval_dim_256_cosine_ndcg@10': 0.8046549711717617, 'eval_dim_256_cosine_mrr@10': 0.7553388702715367, 'eval_dim_256_cosine_map@100': 0.7581336148553626, 'eval_dim_128_cosine_accuracy@1': 0.6442224152910513, 'eval_dim_128_cosine_accuracy@3': 0.8405734144222415, 'eval_dim_128_cosine_accuracy@5': 0.8879235447437012, 'eval_dim_128_cosine_accuracy@10': 0.9500434404865334, 'eval_dim_128_cosine_precision@1': 0.6442224152910513, 'eval_dim_128_cosine_precision@3': 0.2801911381407472, 'eval_dim_128_cosine_precision@5': 0.1775847089487402, 'eval_dim_128_cosine_precision@10': 0.09500434404865332, 'eval_dim_128_cosine_recall@1': 0.6442224152910513, 'eval_dim_128_cosine_recall@3': 0.8405734144222415, 'eval_dim_128_cosine_recall@5': 0.8879235447437012, 'eval_dim_128_cosine_recall@10': 0.9500434404865334, 'eval_dim_128_cosine_ndcg@10': 0.8001701677037015, 'eval_dim_128_cosine_mrr@10': 0.7518963840966431, 'eval_dim_128_cosine_map@100': 0.7551681589446791, 'eval_dim_64_cosine_accuracy@1': 0.5847089487402259, 'eval_dim_64_cosine_accuracy@3': 0.8088618592528236, 'eval_dim_64_cosine_accuracy@5': 0.870981754995656, 'eval_dim_64_cosine_accuracy@10': 0.9409209383145091, 'eval_dim_64_cosine_precision@1': 0.5847089487402259, 'eval_dim_64_cosine_precision@3': 0.2696206197509412, 'eval_dim_64_cosine_precision@5': 0.1741963509991312, 'eval_dim_64_cosine_precision@10': 0.0940920938314509, 'eval_dim_64_cosine_recall@1': 0.5847089487402259, 'eval_dim_64_cosine_recall@3': 0.8088618592528236, 'eval_dim_64_cosine_recall@5': 0.870981754995656, 'eval_dim_64_cosine_recall@10': 0.9409209383145091, 'eval_dim_64_cosine_ndcg@10': 0.7651370587456903, 'eval_dim_64_cosine_mrr@10': 0.7086224194282392, 'eval_dim_64_cosine_map@100': 0.7121203013782961, 'eval_sequential_score': 0.7121203013782961, 'eval_runtime': 42.0278, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 6.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 40/120 [25:02<44:50, 33.63s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2292, 'grad_norm': 3.1116786003112793, 'learning_rate': 1.686241637868734e-05, 'epoch': 8.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 40/120 [25:44<44:50, 33.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6542137271937446, 'eval_dim_768_cosine_accuracy@3': 0.8492615117289314, 'eval_dim_768_cosine_accuracy@5': 0.8979148566463945, 'eval_dim_768_cosine_accuracy@10': 0.9448305821025196, 'eval_dim_768_cosine_precision@1': 0.6542137271937446, 'eval_dim_768_cosine_precision@3': 0.2830871705763104, 'eval_dim_768_cosine_precision@5': 0.1795829713292789, 'eval_dim_768_cosine_precision@10': 0.09448305821025194, 'eval_dim_768_cosine_recall@1': 0.6542137271937446, 'eval_dim_768_cosine_recall@3': 0.8492615117289314, 'eval_dim_768_cosine_recall@5': 0.8979148566463945, 'eval_dim_768_cosine_recall@10': 0.9448305821025196, 'eval_dim_768_cosine_ndcg@10': 0.8044180506351685, 'eval_dim_768_cosine_mrr@10': 0.7588001461806834, 'eval_dim_768_cosine_map@100': 0.7626087324264056, 'eval_dim_512_cosine_accuracy@1': 0.6494352736750652, 'eval_dim_512_cosine_accuracy@3': 0.8423110338835795, 'eval_dim_512_cosine_accuracy@5': 0.8992180712423979, 'eval_dim_512_cosine_accuracy@10': 0.950477845351868, 'eval_dim_512_cosine_precision@1': 0.6494352736750652, 'eval_dim_512_cosine_precision@3': 0.2807703446278598, 'eval_dim_512_cosine_precision@5': 0.17984361424847958, 'eval_dim_512_cosine_precision@10': 0.09504778453518678, 'eval_dim_512_cosine_recall@1': 0.6494352736750652, 'eval_dim_512_cosine_recall@3': 0.8423110338835795, 'eval_dim_512_cosine_recall@5': 0.8992180712423979, 'eval_dim_512_cosine_recall@10': 0.950477845351868, 'eval_dim_512_cosine_ndcg@10': 0.8038878191607408, 'eval_dim_512_cosine_mrr@10': 0.7564424654889459, 'eval_dim_512_cosine_map@100': 0.7599478935268721, 'eval_dim_256_cosine_accuracy@1': 0.6320590790616855, 'eval_dim_256_cosine_accuracy@3': 0.8323197219808862, 'eval_dim_256_cosine_accuracy@5': 0.8935708079930496, 'eval_dim_256_cosine_accuracy@10': 0.9552562988705473, 'eval_dim_256_cosine_precision@1': 0.6320590790616855, 'eval_dim_256_cosine_precision@3': 0.27743990732696205, 'eval_dim_256_cosine_precision@5': 0.17871416159860987, 'eval_dim_256_cosine_precision@10': 0.09552562988705472, 'eval_dim_256_cosine_recall@1': 0.6320590790616855, 'eval_dim_256_cosine_recall@3': 0.8323197219808862, 'eval_dim_256_cosine_recall@5': 0.8935708079930496, 'eval_dim_256_cosine_recall@10': 0.9552562988705473, 'eval_dim_256_cosine_ndcg@10': 0.7969760815594322, 'eval_dim_256_cosine_mrr@10': 0.7459543461172472, 'eval_dim_256_cosine_map@100': 0.749075268550926, 'eval_dim_128_cosine_accuracy@1': 0.634231103388358, 'eval_dim_128_cosine_accuracy@3': 0.8310165073848828, 'eval_dim_128_cosine_accuracy@5': 0.8822762814943528, 'eval_dim_128_cosine_accuracy@10': 0.9465682015638576, 'eval_dim_128_cosine_precision@1': 0.634231103388358, 'eval_dim_128_cosine_precision@3': 0.27700550246162753, 'eval_dim_128_cosine_precision@5': 0.17645525629887052, 'eval_dim_128_cosine_precision@10': 0.09465682015638574, 'eval_dim_128_cosine_recall@1': 0.634231103388358, 'eval_dim_128_cosine_recall@3': 0.8310165073848828, 'eval_dim_128_cosine_recall@5': 0.8822762814943528, 'eval_dim_128_cosine_recall@10': 0.9465682015638576, 'eval_dim_128_cosine_ndcg@10': 0.7932576240970989, 'eval_dim_128_cosine_mrr@10': 0.7438986802366458, 'eval_dim_128_cosine_map@100': 0.747543740111098, 'eval_dim_64_cosine_accuracy@1': 0.5864465682015638, 'eval_dim_64_cosine_accuracy@3': 0.8045178105994787, 'eval_dim_64_cosine_accuracy@5': 0.865768896611642, 'eval_dim_64_cosine_accuracy@10': 0.9413553431798436, 'eval_dim_64_cosine_precision@1': 0.5864465682015638, 'eval_dim_64_cosine_precision@3': 0.2681726035331595, 'eval_dim_64_cosine_precision@5': 0.17315377932232837, 'eval_dim_64_cosine_precision@10': 0.09413553431798435, 'eval_dim_64_cosine_recall@1': 0.5864465682015638, 'eval_dim_64_cosine_recall@3': 0.8045178105994787, 'eval_dim_64_cosine_recall@5': 0.865768896611642, 'eval_dim_64_cosine_recall@10': 0.9413553431798436, 'eval_dim_64_cosine_ndcg@10': 0.7654920455339684, 'eval_dim_64_cosine_mrr@10': 0.7090716492215179, 'eval_dim_64_cosine_map@100': 0.7128069942516603, 'eval_sequential_score': 0.7128069942516603, 'eval_runtime': 42.0058, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 8.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 50/120 [31:35<41:24, 35.49s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1523, 'grad_norm': 4.3719401359558105, 'learning_rate': 1.4487991802004625e-05, 'epoch': 11.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 50/120 [32:17<41:24, 35.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6476976542137272, 'eval_dim_768_cosine_accuracy@3': 0.8331885317115552, 'eval_dim_768_cosine_accuracy@5': 0.8879235447437012, 'eval_dim_768_cosine_accuracy@10': 0.9404865334491747, 'eval_dim_768_cosine_precision@1': 0.6476976542137272, 'eval_dim_768_cosine_precision@3': 0.27772951057051837, 'eval_dim_768_cosine_precision@5': 0.1775847089487402, 'eval_dim_768_cosine_precision@10': 0.09404865334491745, 'eval_dim_768_cosine_recall@1': 0.6476976542137272, 'eval_dim_768_cosine_recall@3': 0.8331885317115552, 'eval_dim_768_cosine_recall@5': 0.8879235447437012, 'eval_dim_768_cosine_recall@10': 0.9404865334491747, 'eval_dim_768_cosine_ndcg@10': 0.7972598799160241, 'eval_dim_768_cosine_mrr@10': 0.7509975797443208, 'eval_dim_768_cosine_map@100': 0.7550072330162996, 'eval_dim_512_cosine_accuracy@1': 0.6498696785403997, 'eval_dim_512_cosine_accuracy@3': 0.8305821025195482, 'eval_dim_512_cosine_accuracy@5': 0.8827106863596872, 'eval_dim_512_cosine_accuracy@10': 0.9426585577758471, 'eval_dim_512_cosine_precision@1': 0.6498696785403997, 'eval_dim_512_cosine_precision@3': 0.27686070083984937, 'eval_dim_512_cosine_precision@5': 0.17654213727193743, 'eval_dim_512_cosine_precision@10': 0.0942658557775847, 'eval_dim_512_cosine_recall@1': 0.6498696785403997, 'eval_dim_512_cosine_recall@3': 0.8305821025195482, 'eval_dim_512_cosine_recall@5': 0.8827106863596872, 'eval_dim_512_cosine_recall@10': 0.9426585577758471, 'eval_dim_512_cosine_ndcg@10': 0.7985173712800921, 'eval_dim_512_cosine_mrr@10': 0.7521154827410246, 'eval_dim_512_cosine_map@100': 0.7561356608910328, 'eval_dim_256_cosine_accuracy@1': 0.635968722849696, 'eval_dim_256_cosine_accuracy@3': 0.8201563857515204, 'eval_dim_256_cosine_accuracy@5': 0.8788010425716768, 'eval_dim_256_cosine_accuracy@10': 0.9491746307558645, 'eval_dim_256_cosine_precision@1': 0.635968722849696, 'eval_dim_256_cosine_precision@3': 0.27338546191717344, 'eval_dim_256_cosine_precision@5': 0.17576020851433535, 'eval_dim_256_cosine_precision@10': 0.09491746307558645, 'eval_dim_256_cosine_recall@1': 0.635968722849696, 'eval_dim_256_cosine_recall@3': 0.8201563857515204, 'eval_dim_256_cosine_recall@5': 0.8788010425716768, 'eval_dim_256_cosine_recall@10': 0.9491746307558645, 'eval_dim_256_cosine_ndcg@10': 0.7935338117330223, 'eval_dim_256_cosine_mrr@10': 0.7436654461958543, 'eval_dim_256_cosine_map@100': 0.7471569804003819, 'eval_dim_128_cosine_accuracy@1': 0.63249348392702, 'eval_dim_128_cosine_accuracy@3': 0.819721980886186, 'eval_dim_128_cosine_accuracy@5': 0.8740225890529973, 'eval_dim_128_cosine_accuracy@10': 0.9400521285838401, 'eval_dim_128_cosine_precision@1': 0.63249348392702, 'eval_dim_128_cosine_precision@3': 0.2732406602953953, 'eval_dim_128_cosine_precision@5': 0.17480451781059947, 'eval_dim_128_cosine_precision@10': 0.09400521285838401, 'eval_dim_128_cosine_recall@1': 0.63249348392702, 'eval_dim_128_cosine_recall@3': 0.819721980886186, 'eval_dim_128_cosine_recall@5': 0.8740225890529973, 'eval_dim_128_cosine_recall@10': 0.9400521285838401, 'eval_dim_128_cosine_ndcg@10': 0.788087917711785, 'eval_dim_128_cosine_mrr@10': 0.7393731124074293, 'eval_dim_128_cosine_map@100': 0.7434763957026908, 'eval_dim_64_cosine_accuracy@1': 0.5899218071242398, 'eval_dim_64_cosine_accuracy@3': 0.7932232841007819, 'eval_dim_64_cosine_accuracy@5': 0.8570807993049522, 'eval_dim_64_cosine_accuracy@10': 0.9391833188531712, 'eval_dim_64_cosine_precision@1': 0.5899218071242398, 'eval_dim_64_cosine_precision@3': 0.2644077613669273, 'eval_dim_64_cosine_precision@5': 0.17141615986099043, 'eval_dim_64_cosine_precision@10': 0.0939183318853171, 'eval_dim_64_cosine_recall@1': 0.5899218071242398, 'eval_dim_64_cosine_recall@3': 0.7932232841007819, 'eval_dim_64_cosine_recall@5': 0.8570807993049522, 'eval_dim_64_cosine_recall@10': 0.9391833188531712, 'eval_dim_64_cosine_ndcg@10': 0.764032486378298, 'eval_dim_64_cosine_mrr@10': 0.7080866534276606, 'eval_dim_64_cosine_map@100': 0.7120240599993348, 'eval_sequential_score': 0.7120240599993348, 'eval_runtime': 41.9956, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 11.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 60/120 [38:03<35:28, 35.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1033, 'grad_norm': 3.720799684524536, 'learning_rate': 1.1736481776669307e-05, 'epoch': 13.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 60/120 [38:45<35:28, 35.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6476976542137272, 'eval_dim_768_cosine_accuracy@3': 0.8305821025195482, 'eval_dim_768_cosine_accuracy@5': 0.8835794960903562, 'eval_dim_768_cosine_accuracy@10': 0.9396177237185056, 'eval_dim_768_cosine_precision@1': 0.6476976542137272, 'eval_dim_768_cosine_precision@3': 0.27686070083984937, 'eval_dim_768_cosine_precision@5': 0.1767158992180712, 'eval_dim_768_cosine_precision@10': 0.09396177237185055, 'eval_dim_768_cosine_recall@1': 0.6476976542137272, 'eval_dim_768_cosine_recall@3': 0.8305821025195482, 'eval_dim_768_cosine_recall@5': 0.8835794960903562, 'eval_dim_768_cosine_recall@10': 0.9396177237185056, 'eval_dim_768_cosine_ndcg@10': 0.7966450368104928, 'eval_dim_768_cosine_mrr@10': 0.7505449022933807, 'eval_dim_768_cosine_map@100': 0.7546402988933104, 'eval_dim_512_cosine_accuracy@1': 0.6490008688097306, 'eval_dim_512_cosine_accuracy@3': 0.8262380538662033, 'eval_dim_512_cosine_accuracy@5': 0.8801042571676803, 'eval_dim_512_cosine_accuracy@10': 0.9413553431798436, 'eval_dim_512_cosine_precision@1': 0.6490008688097306, 'eval_dim_512_cosine_precision@3': 0.27541268462206775, 'eval_dim_512_cosine_precision@5': 0.17602085143353605, 'eval_dim_512_cosine_precision@10': 0.09413553431798435, 'eval_dim_512_cosine_recall@1': 0.6490008688097306, 'eval_dim_512_cosine_recall@3': 0.8262380538662033, 'eval_dim_512_cosine_recall@5': 0.8801042571676803, 'eval_dim_512_cosine_recall@10': 0.9413553431798436, 'eval_dim_512_cosine_ndcg@10': 0.7971588846861433, 'eval_dim_512_cosine_mrr@10': 0.750795719388247, 'eval_dim_512_cosine_map@100': 0.754842261021175, 'eval_dim_256_cosine_accuracy@1': 0.6442224152910513, 'eval_dim_256_cosine_accuracy@3': 0.8158123370981755, 'eval_dim_256_cosine_accuracy@5': 0.8774978279756733, 'eval_dim_256_cosine_accuracy@10': 0.946133796698523, 'eval_dim_256_cosine_precision@1': 0.6442224152910513, 'eval_dim_256_cosine_precision@3': 0.2719374456993918, 'eval_dim_256_cosine_precision@5': 0.17549956559513466, 'eval_dim_256_cosine_precision@10': 0.09461337966985228, 'eval_dim_256_cosine_recall@1': 0.6442224152910513, 'eval_dim_256_cosine_recall@3': 0.8158123370981755, 'eval_dim_256_cosine_recall@5': 0.8774978279756733, 'eval_dim_256_cosine_recall@10': 0.946133796698523, 'eval_dim_256_cosine_ndcg@10': 0.7949406091362343, 'eval_dim_256_cosine_mrr@10': 0.746697316343276, 'eval_dim_256_cosine_map@100': 0.7505163042553262, 'eval_dim_128_cosine_accuracy@1': 0.634231103388358, 'eval_dim_128_cosine_accuracy@3': 0.81624674196351, 'eval_dim_128_cosine_accuracy@5': 0.8757602085143353, 'eval_dim_128_cosine_accuracy@10': 0.9387489139878367, 'eval_dim_128_cosine_precision@1': 0.634231103388358, 'eval_dim_128_cosine_precision@3': 0.27208224732117, 'eval_dim_128_cosine_precision@5': 0.17515204170286705, 'eval_dim_128_cosine_precision@10': 0.09387489139878365, 'eval_dim_128_cosine_recall@1': 0.634231103388358, 'eval_dim_128_cosine_recall@3': 0.81624674196351, 'eval_dim_128_cosine_recall@5': 0.8757602085143353, 'eval_dim_128_cosine_recall@10': 0.9387489139878367, 'eval_dim_128_cosine_ndcg@10': 0.7884782415836458, 'eval_dim_128_cosine_mrr@10': 0.7402196847461826, 'eval_dim_128_cosine_map@100': 0.7445853004628855, 'eval_dim_64_cosine_accuracy@1': 0.6007819287576021, 'eval_dim_64_cosine_accuracy@3': 0.789748045178106, 'eval_dim_64_cosine_accuracy@5': 0.8557775847089487, 'eval_dim_64_cosine_accuracy@10': 0.9361424847958297, 'eval_dim_64_cosine_precision@1': 0.6007819287576021, 'eval_dim_64_cosine_precision@3': 0.263249348392702, 'eval_dim_64_cosine_precision@5': 0.17115551694178974, 'eval_dim_64_cosine_precision@10': 0.09361424847958295, 'eval_dim_64_cosine_recall@1': 0.6007819287576021, 'eval_dim_64_cosine_recall@3': 0.789748045178106, 'eval_dim_64_cosine_recall@5': 0.8557775847089487, 'eval_dim_64_cosine_recall@10': 0.9361424847958297, 'eval_dim_64_cosine_ndcg@10': 0.7669429677039482, 'eval_dim_64_cosine_mrr@10': 0.7129992208293673, 'eval_dim_64_cosine_map@100': 0.7172205117527618, 'eval_sequential_score': 0.7172205117527618, 'eval_runtime': 42.1383, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 13.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 70/120 [44:30<29:17, 35.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.072, 'grad_norm': 3.760728597640991, 'learning_rate': 8.839070858747697e-06, 'epoch': 15.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 70/120 [45:12<29:17, 35.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6429192006950478, 'eval_dim_768_cosine_accuracy@3': 0.8236316246741964, 'eval_dim_768_cosine_accuracy@5': 0.8827106863596872, 'eval_dim_768_cosine_accuracy@10': 0.9422241529105126, 'eval_dim_768_cosine_precision@1': 0.6429192006950478, 'eval_dim_768_cosine_precision@3': 0.2745438748913988, 'eval_dim_768_cosine_precision@5': 0.1765421372719374, 'eval_dim_768_cosine_precision@10': 0.09422241529105126, 'eval_dim_768_cosine_recall@1': 0.6429192006950478, 'eval_dim_768_cosine_recall@3': 0.8236316246741964, 'eval_dim_768_cosine_recall@5': 0.8827106863596872, 'eval_dim_768_cosine_recall@10': 0.9422241529105126, 'eval_dim_768_cosine_ndcg@10': 0.7940848894749082, 'eval_dim_768_cosine_mrr@10': 0.7465006274736936, 'eval_dim_768_cosine_map@100': 0.7504106850354332, 'eval_dim_512_cosine_accuracy@1': 0.6437880104257168, 'eval_dim_512_cosine_accuracy@3': 0.8275412684622068, 'eval_dim_512_cosine_accuracy@5': 0.8770634231103388, 'eval_dim_512_cosine_accuracy@10': 0.9456993918331885, 'eval_dim_512_cosine_precision@1': 0.6437880104257168, 'eval_dim_512_cosine_precision@3': 0.2758470894874023, 'eval_dim_512_cosine_precision@5': 0.17541268462206774, 'eval_dim_512_cosine_precision@10': 0.09456993918331884, 'eval_dim_512_cosine_recall@1': 0.6437880104257168, 'eval_dim_512_cosine_recall@3': 0.8275412684622068, 'eval_dim_512_cosine_recall@5': 0.8770634231103388, 'eval_dim_512_cosine_recall@10': 0.9456993918331885, 'eval_dim_512_cosine_ndcg@10': 0.7963415568592718, 'eval_dim_512_cosine_mrr@10': 0.748442520651469, 'eval_dim_512_cosine_map@100': 0.752138289874721, 'eval_dim_256_cosine_accuracy@1': 0.6372719374456994, 'eval_dim_256_cosine_accuracy@3': 0.8136403127715031, 'eval_dim_256_cosine_accuracy@5': 0.8731537793223284, 'eval_dim_256_cosine_accuracy@10': 0.946133796698523, 'eval_dim_256_cosine_precision@1': 0.6372719374456994, 'eval_dim_256_cosine_precision@3': 0.271213437590501, 'eval_dim_256_cosine_precision@5': 0.17463075586446566, 'eval_dim_256_cosine_precision@10': 0.0946133796698523, 'eval_dim_256_cosine_recall@1': 0.6372719374456994, 'eval_dim_256_cosine_recall@3': 0.8136403127715031, 'eval_dim_256_cosine_recall@5': 0.8731537793223284, 'eval_dim_256_cosine_recall@10': 0.946133796698523, 'eval_dim_256_cosine_ndcg@10': 0.791466131293951, 'eval_dim_256_cosine_mrr@10': 0.7420734902707092, 'eval_dim_256_cosine_map@100': 0.7459257977257435, 'eval_dim_128_cosine_accuracy@1': 0.6272806255430061, 'eval_dim_128_cosine_accuracy@3': 0.8201563857515204, 'eval_dim_128_cosine_accuracy@5': 0.8761946133796699, 'eval_dim_128_cosine_accuracy@10': 0.9426585577758471, 'eval_dim_128_cosine_precision@1': 0.6272806255430061, 'eval_dim_128_cosine_precision@3': 0.27338546191717344, 'eval_dim_128_cosine_precision@5': 0.17523892267593397, 'eval_dim_128_cosine_precision@10': 0.0942658557775847, 'eval_dim_128_cosine_recall@1': 0.6272806255430061, 'eval_dim_128_cosine_recall@3': 0.8201563857515204, 'eval_dim_128_cosine_recall@5': 0.8761946133796699, 'eval_dim_128_cosine_recall@10': 0.9426585577758471, 'eval_dim_128_cosine_ndcg@10': 0.7874161515136968, 'eval_dim_128_cosine_mrr@10': 0.7375272364955244, 'eval_dim_128_cosine_map@100': 0.7416133183311138, 'eval_dim_64_cosine_accuracy@1': 0.5999131190269331, 'eval_dim_64_cosine_accuracy@3': 0.7927888792354474, 'eval_dim_64_cosine_accuracy@5': 0.8605560382276282, 'eval_dim_64_cosine_accuracy@10': 0.9361424847958297, 'eval_dim_64_cosine_precision@1': 0.5999131190269331, 'eval_dim_64_cosine_precision@3': 0.26426295974514913, 'eval_dim_64_cosine_precision@5': 0.1721112076455256, 'eval_dim_64_cosine_precision@10': 0.09361424847958295, 'eval_dim_64_cosine_recall@1': 0.5999131190269331, 'eval_dim_64_cosine_recall@3': 0.7927888792354474, 'eval_dim_64_cosine_recall@5': 0.8605560382276282, 'eval_dim_64_cosine_recall@10': 0.9361424847958297, 'eval_dim_64_cosine_ndcg@10': 0.7669748278626208, 'eval_dim_64_cosine_mrr@10': 0.7130090466537027, 'eval_dim_64_cosine_map@100': 0.7172793297082963, 'eval_sequential_score': 0.7172793297082963, 'eval_runtime': 41.9384, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 15.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 80/120 [50:54<22:52, 34.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0587, 'grad_norm': 1.4197888374328613, 'learning_rate': 6.039202339608432e-06, 'epoch': 17.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 80/120 [51:36<22:52, 34.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6485664639443962, 'eval_dim_768_cosine_accuracy@3': 0.8301476976542137, 'eval_dim_768_cosine_accuracy@5': 0.8861859252823632, 'eval_dim_768_cosine_accuracy@10': 0.9435273675065161, 'eval_dim_768_cosine_precision@1': 0.6485664639443962, 'eval_dim_768_cosine_precision@3': 0.2767158992180712, 'eval_dim_768_cosine_precision@5': 0.17723718505647262, 'eval_dim_768_cosine_precision@10': 0.09435273675065159, 'eval_dim_768_cosine_recall@1': 0.6485664639443962, 'eval_dim_768_cosine_recall@3': 0.8301476976542137, 'eval_dim_768_cosine_recall@5': 0.8861859252823632, 'eval_dim_768_cosine_recall@10': 0.9435273675065161, 'eval_dim_768_cosine_ndcg@10': 0.7985587885695002, 'eval_dim_768_cosine_mrr@10': 0.7518588046281349, 'eval_dim_768_cosine_map@100': 0.7557425865771096, 'eval_dim_512_cosine_accuracy@1': 0.6503040834057341, 'eval_dim_512_cosine_accuracy@3': 0.8297132927888793, 'eval_dim_512_cosine_accuracy@5': 0.8814074717636837, 'eval_dim_512_cosine_accuracy@10': 0.9465682015638576, 'eval_dim_512_cosine_precision@1': 0.6503040834057341, 'eval_dim_512_cosine_precision@3': 0.27657109759629306, 'eval_dim_512_cosine_precision@5': 0.17628149435273674, 'eval_dim_512_cosine_precision@10': 0.09465682015638574, 'eval_dim_512_cosine_recall@1': 0.6503040834057341, 'eval_dim_512_cosine_recall@3': 0.8297132927888793, 'eval_dim_512_cosine_recall@5': 0.8814074717636837, 'eval_dim_512_cosine_recall@10': 0.9465682015638576, 'eval_dim_512_cosine_ndcg@10': 0.8000076563022006, 'eval_dim_512_cosine_mrr@10': 0.7529660198860884, 'eval_dim_512_cosine_map@100': 0.7567240182674079, 'eval_dim_256_cosine_accuracy@1': 0.6468288444830582, 'eval_dim_256_cosine_accuracy@3': 0.8201563857515204, 'eval_dim_256_cosine_accuracy@5': 0.8831450912250217, 'eval_dim_256_cosine_accuracy@10': 0.9496090356211989, 'eval_dim_256_cosine_precision@1': 0.6468288444830582, 'eval_dim_256_cosine_precision@3': 0.27338546191717344, 'eval_dim_256_cosine_precision@5': 0.17662901824500432, 'eval_dim_256_cosine_precision@10': 0.09496090356211988, 'eval_dim_256_cosine_recall@1': 0.6468288444830582, 'eval_dim_256_cosine_recall@3': 0.8201563857515204, 'eval_dim_256_cosine_recall@5': 0.8831450912250217, 'eval_dim_256_cosine_recall@10': 0.9496090356211989, 'eval_dim_256_cosine_ndcg@10': 0.7980713216571041, 'eval_dim_256_cosine_mrr@10': 0.7496433398149293, 'eval_dim_256_cosine_map@100': 0.7532742194467413, 'eval_dim_128_cosine_accuracy@1': 0.6381407471763684, 'eval_dim_128_cosine_accuracy@3': 0.8245004344048653, 'eval_dim_128_cosine_accuracy@5': 0.8809730668983493, 'eval_dim_128_cosine_accuracy@10': 0.9448305821025196, 'eval_dim_128_cosine_precision@1': 0.6381407471763684, 'eval_dim_128_cosine_precision@3': 0.2748334781349551, 'eval_dim_128_cosine_precision@5': 0.17619461337966985, 'eval_dim_128_cosine_precision@10': 0.09448305821025195, 'eval_dim_128_cosine_recall@1': 0.6381407471763684, 'eval_dim_128_cosine_recall@3': 0.8245004344048653, 'eval_dim_128_cosine_recall@5': 0.8809730668983493, 'eval_dim_128_cosine_recall@10': 0.9448305821025196, 'eval_dim_128_cosine_ndcg@10': 0.7938430035815471, 'eval_dim_128_cosine_mrr@10': 0.7453032559678946, 'eval_dim_128_cosine_map@100': 0.7492228197749221, 'eval_dim_64_cosine_accuracy@1': 0.6038227628149435, 'eval_dim_64_cosine_accuracy@3': 0.7962641181581234, 'eval_dim_64_cosine_accuracy@5': 0.8635968722849696, 'eval_dim_64_cosine_accuracy@10': 0.9413553431798436, 'eval_dim_64_cosine_precision@1': 0.6038227628149435, 'eval_dim_64_cosine_precision@3': 0.26542137271937444, 'eval_dim_64_cosine_precision@5': 0.17271937445699387, 'eval_dim_64_cosine_precision@10': 0.09413553431798434, 'eval_dim_64_cosine_recall@1': 0.6038227628149435, 'eval_dim_64_cosine_recall@3': 0.7962641181581234, 'eval_dim_64_cosine_recall@5': 0.8635968722849696, 'eval_dim_64_cosine_recall@10': 0.9413553431798436, 'eval_dim_64_cosine_ndcg@10': 0.7715478287720181, 'eval_dim_64_cosine_mrr@10': 0.7174756595369095, 'eval_dim_64_cosine_map@100': 0.7213400239274025, 'eval_sequential_score': 0.7213400239274025, 'eval_runtime': 41.9325, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 17.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 90/120 [57:14<16:15, 32.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0544, 'grad_norm': 2.2262110710144043, 'learning_rate': 3.5721239031346067e-06, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 90/120 [57:56<16:15, 32.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6424847958297133, 'eval_dim_768_cosine_accuracy@3': 0.8288444830582102, 'eval_dim_768_cosine_accuracy@5': 0.8840139009556907, 'eval_dim_768_cosine_accuracy@10': 0.9430929626411816, 'eval_dim_768_cosine_precision@1': 0.6424847958297133, 'eval_dim_768_cosine_precision@3': 0.27628149435273675, 'eval_dim_768_cosine_precision@5': 0.17680278019113815, 'eval_dim_768_cosine_precision@10': 0.09430929626411814, 'eval_dim_768_cosine_recall@1': 0.6424847958297133, 'eval_dim_768_cosine_recall@3': 0.8288444830582102, 'eval_dim_768_cosine_recall@5': 0.8840139009556907, 'eval_dim_768_cosine_recall@10': 0.9430929626411816, 'eval_dim_768_cosine_ndcg@10': 0.7954273121476143, 'eval_dim_768_cosine_mrr@10': 0.7478512473625409, 'eval_dim_768_cosine_map@100': 0.7517847335646215, 'eval_dim_512_cosine_accuracy@1': 0.6437880104257168, 'eval_dim_512_cosine_accuracy@3': 0.8297132927888793, 'eval_dim_512_cosine_accuracy@5': 0.8801042571676803, 'eval_dim_512_cosine_accuracy@10': 0.947002606429192, 'eval_dim_512_cosine_precision@1': 0.6437880104257168, 'eval_dim_512_cosine_precision@3': 0.27657109759629306, 'eval_dim_512_cosine_precision@5': 0.17602085143353602, 'eval_dim_512_cosine_precision@10': 0.09470026064291918, 'eval_dim_512_cosine_recall@1': 0.6437880104257168, 'eval_dim_512_cosine_recall@3': 0.8297132927888793, 'eval_dim_512_cosine_recall@5': 0.8801042571676803, 'eval_dim_512_cosine_recall@10': 0.947002606429192, 'eval_dim_512_cosine_ndcg@10': 0.7970978464446589, 'eval_dim_512_cosine_mrr@10': 0.7489908706025118, 'eval_dim_512_cosine_map@100': 0.7527071632360477, 'eval_dim_256_cosine_accuracy@1': 0.6433536055603822, 'eval_dim_256_cosine_accuracy@3': 0.8214596003475239, 'eval_dim_256_cosine_accuracy@5': 0.8818418766290183, 'eval_dim_256_cosine_accuracy@10': 0.9474370112945265, 'eval_dim_256_cosine_precision@1': 0.6433536055603822, 'eval_dim_256_cosine_precision@3': 0.2738198667825079, 'eval_dim_256_cosine_precision@5': 0.17636837532580363, 'eval_dim_256_cosine_precision@10': 0.09474370112945263, 'eval_dim_256_cosine_recall@1': 0.6433536055603822, 'eval_dim_256_cosine_recall@3': 0.8214596003475239, 'eval_dim_256_cosine_recall@5': 0.8818418766290183, 'eval_dim_256_cosine_recall@10': 0.9474370112945265, 'eval_dim_256_cosine_ndcg@10': 0.7960955526822666, 'eval_dim_256_cosine_mrr@10': 0.7476381821190679, 'eval_dim_256_cosine_map@100': 0.7514204647812432, 'eval_dim_128_cosine_accuracy@1': 0.6372719374456994, 'eval_dim_128_cosine_accuracy@3': 0.8214596003475239, 'eval_dim_128_cosine_accuracy@5': 0.8788010425716768, 'eval_dim_128_cosine_accuracy@10': 0.9439617723718505, 'eval_dim_128_cosine_precision@1': 0.6372719374456994, 'eval_dim_128_cosine_precision@3': 0.2738198667825079, 'eval_dim_128_cosine_precision@5': 0.17576020851433535, 'eval_dim_128_cosine_precision@10': 0.09439617723718505, 'eval_dim_128_cosine_recall@1': 0.6372719374456994, 'eval_dim_128_cosine_recall@3': 0.8214596003475239, 'eval_dim_128_cosine_recall@5': 0.8788010425716768, 'eval_dim_128_cosine_recall@10': 0.9439617723718505, 'eval_dim_128_cosine_ndcg@10': 0.7923989589534627, 'eval_dim_128_cosine_mrr@10': 0.743770599754526, 'eval_dim_128_cosine_map@100': 0.7477033203419167, 'eval_dim_64_cosine_accuracy@1': 0.5994787141615986, 'eval_dim_64_cosine_accuracy@3': 0.7953953084274544, 'eval_dim_64_cosine_accuracy@5': 0.8596872284969591, 'eval_dim_64_cosine_accuracy@10': 0.9417897480451781, 'eval_dim_64_cosine_precision@1': 0.5994787141615986, 'eval_dim_64_cosine_precision@3': 0.26513176947581807, 'eval_dim_64_cosine_precision@5': 0.17193744569939182, 'eval_dim_64_cosine_precision@10': 0.09417897480451778, 'eval_dim_64_cosine_recall@1': 0.5994787141615986, 'eval_dim_64_cosine_recall@3': 0.7953953084274544, 'eval_dim_64_cosine_recall@5': 0.8596872284969591, 'eval_dim_64_cosine_recall@10': 0.9417897480451781, 'eval_dim_64_cosine_ndcg@10': 0.7694986322860453, 'eval_dim_64_cosine_mrr@10': 0.7147066732861682, 'eval_dim_64_cosine_map@100': 0.7185486212639801, 'eval_sequential_score': 0.7185486212639801, 'eval_runtime': 41.9965, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 100/120 [1:03:43<11:16, 33.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.052, 'grad_norm': 1.119154691696167, 'learning_rate': 1.6451218858706374e-06, 'epoch': 22.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 100/120 [1:04:25<11:16, 33.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6407471763683753, 'eval_dim_768_cosine_accuracy@3': 0.8258036490008688, 'eval_dim_768_cosine_accuracy@5': 0.8840139009556907, 'eval_dim_768_cosine_accuracy@10': 0.944396177237185, 'eval_dim_768_cosine_precision@1': 0.6407471763683753, 'eval_dim_768_cosine_precision@3': 0.27526788300028954, 'eval_dim_768_cosine_precision@5': 0.17680278019113813, 'eval_dim_768_cosine_precision@10': 0.09443961772371849, 'eval_dim_768_cosine_recall@1': 0.6407471763683753, 'eval_dim_768_cosine_recall@3': 0.8258036490008688, 'eval_dim_768_cosine_recall@5': 0.8840139009556907, 'eval_dim_768_cosine_recall@10': 0.944396177237185, 'eval_dim_768_cosine_ndcg@10': 0.7948630454288174, 'eval_dim_768_cosine_mrr@10': 0.746743170190172, 'eval_dim_768_cosine_map@100': 0.750561042319851, 'eval_dim_512_cosine_accuracy@1': 0.6424847958297133, 'eval_dim_512_cosine_accuracy@3': 0.8301476976542137, 'eval_dim_512_cosine_accuracy@5': 0.8788010425716768, 'eval_dim_512_cosine_accuracy@10': 0.9465682015638576, 'eval_dim_512_cosine_precision@1': 0.6424847958297133, 'eval_dim_512_cosine_precision@3': 0.2767158992180712, 'eval_dim_512_cosine_precision@5': 0.17576020851433535, 'eval_dim_512_cosine_precision@10': 0.09465682015638574, 'eval_dim_512_cosine_recall@1': 0.6424847958297133, 'eval_dim_512_cosine_recall@3': 0.8301476976542137, 'eval_dim_512_cosine_recall@5': 0.8788010425716768, 'eval_dim_512_cosine_recall@10': 0.9465682015638576, 'eval_dim_512_cosine_ndcg@10': 0.7966461025271516, 'eval_dim_512_cosine_mrr@10': 0.748508715678567, 'eval_dim_512_cosine_map@100': 0.7522630680347415, 'eval_dim_256_cosine_accuracy@1': 0.6416159860990444, 'eval_dim_256_cosine_accuracy@3': 0.8210251954821894, 'eval_dim_256_cosine_accuracy@5': 0.8814074717636837, 'eval_dim_256_cosine_accuracy@10': 0.947002606429192, 'eval_dim_256_cosine_precision@1': 0.6416159860990444, 'eval_dim_256_cosine_precision@3': 0.2736750651607298, 'eval_dim_256_cosine_precision@5': 0.17628149435273674, 'eval_dim_256_cosine_precision@10': 0.09470026064291918, 'eval_dim_256_cosine_recall@1': 0.6416159860990444, 'eval_dim_256_cosine_recall@3': 0.8210251954821894, 'eval_dim_256_cosine_recall@5': 0.8814074717636837, 'eval_dim_256_cosine_recall@10': 0.947002606429192, 'eval_dim_256_cosine_ndcg@10': 0.794772864646991, 'eval_dim_256_cosine_mrr@10': 0.7460400204101325, 'eval_dim_256_cosine_map@100': 0.7498457336550931, 'eval_dim_128_cosine_accuracy@1': 0.6385751520417029, 'eval_dim_128_cosine_accuracy@3': 0.8227628149435273, 'eval_dim_128_cosine_accuracy@5': 0.8770634231103388, 'eval_dim_128_cosine_accuracy@10': 0.9435273675065161, 'eval_dim_128_cosine_precision@1': 0.6385751520417029, 'eval_dim_128_cosine_precision@3': 0.27425427164784244, 'eval_dim_128_cosine_precision@5': 0.17541268462206774, 'eval_dim_128_cosine_precision@10': 0.0943527367506516, 'eval_dim_128_cosine_recall@1': 0.6385751520417029, 'eval_dim_128_cosine_recall@3': 0.8227628149435273, 'eval_dim_128_cosine_recall@5': 0.8770634231103388, 'eval_dim_128_cosine_recall@10': 0.9435273675065161, 'eval_dim_128_cosine_ndcg@10': 0.7930898218620375, 'eval_dim_128_cosine_mrr@10': 0.744808517093486, 'eval_dim_128_cosine_map@100': 0.7487768111738856, 'eval_dim_64_cosine_accuracy@1': 0.6038227628149435, 'eval_dim_64_cosine_accuracy@3': 0.7962641181581234, 'eval_dim_64_cosine_accuracy@5': 0.8601216333622936, 'eval_dim_64_cosine_accuracy@10': 0.9435273675065161, 'eval_dim_64_cosine_precision@1': 0.6038227628149435, 'eval_dim_64_cosine_precision@3': 0.26542137271937444, 'eval_dim_64_cosine_precision@5': 0.17202432667245873, 'eval_dim_64_cosine_precision@10': 0.0943527367506516, 'eval_dim_64_cosine_recall@1': 0.6038227628149435, 'eval_dim_64_cosine_recall@3': 0.7962641181581234, 'eval_dim_64_cosine_recall@5': 0.8601216333622936, 'eval_dim_64_cosine_recall@10': 0.9435273675065161, 'eval_dim_64_cosine_ndcg@10': 0.7716068065088058, 'eval_dim_64_cosine_mrr@10': 0.7170560795995189, 'eval_dim_64_cosine_map@100': 0.720746256041526, 'eval_sequential_score': 0.720746256041526, 'eval_runtime': 41.9223, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 22.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 110/120 [1:10:12<05:48, 34.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0507, 'grad_norm': 3.916719913482666, 'learning_rate': 4.2010487684511105e-07, 'epoch': 24.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 110/120 [1:10:54<05:48, 34.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6424847958297133, 'eval_dim_768_cosine_accuracy@3': 0.8275412684622068, 'eval_dim_768_cosine_accuracy@5': 0.8840139009556907, 'eval_dim_768_cosine_accuracy@10': 0.9448305821025196, 'eval_dim_768_cosine_precision@1': 0.6424847958297133, 'eval_dim_768_cosine_precision@3': 0.2758470894874023, 'eval_dim_768_cosine_precision@5': 0.17680278019113815, 'eval_dim_768_cosine_precision@10': 0.09448305821025194, 'eval_dim_768_cosine_recall@1': 0.6424847958297133, 'eval_dim_768_cosine_recall@3': 0.8275412684622068, 'eval_dim_768_cosine_recall@5': 0.8840139009556907, 'eval_dim_768_cosine_recall@10': 0.9448305821025196, 'eval_dim_768_cosine_ndcg@10': 0.7958479336753231, 'eval_dim_768_cosine_mrr@10': 0.7479177871554059, 'eval_dim_768_cosine_map@100': 0.7516998684461761, 'eval_dim_512_cosine_accuracy@1': 0.6459600347523893, 'eval_dim_512_cosine_accuracy@3': 0.8305821025195482, 'eval_dim_512_cosine_accuracy@5': 0.8783666377063423, 'eval_dim_512_cosine_accuracy@10': 0.9465682015638576, 'eval_dim_512_cosine_precision@1': 0.6459600347523893, 'eval_dim_512_cosine_precision@3': 0.27686070083984937, 'eval_dim_512_cosine_precision@5': 0.17567332754126844, 'eval_dim_512_cosine_precision@10': 0.09465682015638574, 'eval_dim_512_cosine_recall@1': 0.6459600347523893, 'eval_dim_512_cosine_recall@3': 0.8305821025195482, 'eval_dim_512_cosine_recall@5': 0.8783666377063423, 'eval_dim_512_cosine_recall@10': 0.9465682015638576, 'eval_dim_512_cosine_ndcg@10': 0.7979860743915834, 'eval_dim_512_cosine_mrr@10': 0.7503023595769027, 'eval_dim_512_cosine_map@100': 0.7540504279396324, 'eval_dim_256_cosine_accuracy@1': 0.6424847958297133, 'eval_dim_256_cosine_accuracy@3': 0.8218940052128584, 'eval_dim_256_cosine_accuracy@5': 0.8796698523023457, 'eval_dim_256_cosine_accuracy@10': 0.9483058210251955, 'eval_dim_256_cosine_precision@1': 0.6424847958297133, 'eval_dim_256_cosine_precision@3': 0.2739646684042861, 'eval_dim_256_cosine_precision@5': 0.17593397046046913, 'eval_dim_256_cosine_precision@10': 0.09483058210251955, 'eval_dim_256_cosine_recall@1': 0.6424847958297133, 'eval_dim_256_cosine_recall@3': 0.8218940052128584, 'eval_dim_256_cosine_recall@5': 0.8796698523023457, 'eval_dim_256_cosine_recall@10': 0.9483058210251955, 'eval_dim_256_cosine_ndcg@10': 0.795576070334861, 'eval_dim_256_cosine_mrr@10': 0.7467212775640221, 'eval_dim_256_cosine_map@100': 0.7504158161013519, 'eval_dim_128_cosine_accuracy@1': 0.6385751520417029, 'eval_dim_128_cosine_accuracy@3': 0.8218940052128584, 'eval_dim_128_cosine_accuracy@5': 0.8774978279756733, 'eval_dim_128_cosine_accuracy@10': 0.9435273675065161, 'eval_dim_128_cosine_precision@1': 0.6385751520417029, 'eval_dim_128_cosine_precision@3': 0.2739646684042861, 'eval_dim_128_cosine_precision@5': 0.17549956559513463, 'eval_dim_128_cosine_precision@10': 0.09435273675065159, 'eval_dim_128_cosine_recall@1': 0.6385751520417029, 'eval_dim_128_cosine_recall@3': 0.8218940052128584, 'eval_dim_128_cosine_recall@5': 0.8774978279756733, 'eval_dim_128_cosine_recall@10': 0.9435273675065161, 'eval_dim_128_cosine_ndcg@10': 0.7931569243694906, 'eval_dim_128_cosine_mrr@10': 0.7448978114269159, 'eval_dim_128_cosine_map@100': 0.7488765538312033, 'eval_dim_64_cosine_accuracy@1': 0.6055603822762815, 'eval_dim_64_cosine_accuracy@3': 0.7971329278887923, 'eval_dim_64_cosine_accuracy@5': 0.8596872284969591, 'eval_dim_64_cosine_accuracy@10': 0.9422241529105126, 'eval_dim_64_cosine_precision@1': 0.6055603822762815, 'eval_dim_64_cosine_precision@3': 0.26571097596293075, 'eval_dim_64_cosine_precision@5': 0.17193744569939182, 'eval_dim_64_cosine_precision@10': 0.09422241529105126, 'eval_dim_64_cosine_recall@1': 0.6055603822762815, 'eval_dim_64_cosine_recall@3': 0.7971329278887923, 'eval_dim_64_cosine_recall@5': 0.8596872284969591, 'eval_dim_64_cosine_recall@10': 0.9422241529105126, 'eval_dim_64_cosine_ndcg@10': 0.7720990495786183, 'eval_dim_64_cosine_mrr@10': 0.7180469364114012, 'eval_dim_64_cosine_map@100': 0.7218540289451466, 'eval_sequential_score': 0.7218540289451466, 'eval_runtime': 41.9226, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 24.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [1:16:41<00:00, 35.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0463, 'grad_norm': 1.7233991622924805, 'learning_rate': 0.0, 'epoch': 26.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [1:17:23<00:00, 35.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_dim_768_cosine_accuracy@1': 0.6416159860990444, 'eval_dim_768_cosine_accuracy@3': 0.8284100781928757, 'eval_dim_768_cosine_accuracy@5': 0.8844483058210252, 'eval_dim_768_cosine_accuracy@10': 0.944396177237185, 'eval_dim_768_cosine_precision@1': 0.6416159860990444, 'eval_dim_768_cosine_precision@3': 0.2761366927309586, 'eval_dim_768_cosine_precision@5': 0.17688966116420504, 'eval_dim_768_cosine_precision@10': 0.09443961772371849, 'eval_dim_768_cosine_recall@1': 0.6416159860990444, 'eval_dim_768_cosine_recall@3': 0.8284100781928757, 'eval_dim_768_cosine_recall@5': 0.8844483058210252, 'eval_dim_768_cosine_recall@10': 0.944396177237185, 'eval_dim_768_cosine_ndcg@10': 0.7955669732681404, 'eval_dim_768_cosine_mrr@10': 0.7476478355605195, 'eval_dim_768_cosine_map@100': 0.7514706688798185, 'eval_dim_512_cosine_accuracy@1': 0.6463944396177237, 'eval_dim_512_cosine_accuracy@3': 0.8301476976542137, 'eval_dim_512_cosine_accuracy@5': 0.8805386620330148, 'eval_dim_512_cosine_accuracy@10': 0.9465682015638576, 'eval_dim_512_cosine_precision@1': 0.6463944396177237, 'eval_dim_512_cosine_precision@3': 0.2767158992180712, 'eval_dim_512_cosine_precision@5': 0.17610773240660293, 'eval_dim_512_cosine_precision@10': 0.09465682015638574, 'eval_dim_512_cosine_recall@1': 0.6463944396177237, 'eval_dim_512_cosine_recall@3': 0.8301476976542137, 'eval_dim_512_cosine_recall@5': 0.8805386620330148, 'eval_dim_512_cosine_recall@10': 0.9465682015638576, 'eval_dim_512_cosine_ndcg@10': 0.7982013047416887, 'eval_dim_512_cosine_mrr@10': 0.750589721842979, 'eval_dim_512_cosine_map@100': 0.7543427771113016, 'eval_dim_256_cosine_accuracy@1': 0.6416159860990444, 'eval_dim_256_cosine_accuracy@3': 0.8223284100781929, 'eval_dim_256_cosine_accuracy@5': 0.8805386620330148, 'eval_dim_256_cosine_accuracy@10': 0.9474370112945265, 'eval_dim_256_cosine_precision@1': 0.6416159860990444, 'eval_dim_256_cosine_precision@3': 0.2741094700260643, 'eval_dim_256_cosine_precision@5': 0.17610773240660293, 'eval_dim_256_cosine_precision@10': 0.09474370112945263, 'eval_dim_256_cosine_recall@1': 0.6416159860990444, 'eval_dim_256_cosine_recall@3': 0.8223284100781929, 'eval_dim_256_cosine_recall@5': 0.8805386620330148, 'eval_dim_256_cosine_recall@10': 0.9474370112945265, 'eval_dim_256_cosine_ndcg@10': 0.7952322627983576, 'eval_dim_256_cosine_mrr@10': 0.7464958007529674, 'eval_dim_256_cosine_map@100': 0.7502726797533102, 'eval_dim_128_cosine_accuracy@1': 0.6368375325803649, 'eval_dim_128_cosine_accuracy@3': 0.8205907906168549, 'eval_dim_128_cosine_accuracy@5': 0.8766290182450044, 'eval_dim_128_cosine_accuracy@10': 0.9439617723718505, 'eval_dim_128_cosine_precision@1': 0.6368375325803649, 'eval_dim_128_cosine_precision@3': 0.2735302635389516, 'eval_dim_128_cosine_precision@5': 0.17532580364900086, 'eval_dim_128_cosine_precision@10': 0.09439617723718503, 'eval_dim_128_cosine_recall@1': 0.6368375325803649, 'eval_dim_128_cosine_recall@3': 0.8205907906168549, 'eval_dim_128_cosine_recall@5': 0.8766290182450044, 'eval_dim_128_cosine_recall@10': 0.9439617723718505, 'eval_dim_128_cosine_ndcg@10': 0.7923718738543776, 'eval_dim_128_cosine_mrr@10': 0.7437235392274483, 'eval_dim_128_cosine_map@100': 0.7476634938521087, 'eval_dim_64_cosine_accuracy@1': 0.606863596872285, 'eval_dim_64_cosine_accuracy@3': 0.7975673327541268, 'eval_dim_64_cosine_accuracy@5': 0.8601216333622936, 'eval_dim_64_cosine_accuracy@10': 0.9417897480451781, 'eval_dim_64_cosine_precision@1': 0.606863596872285, 'eval_dim_64_cosine_precision@3': 0.26585577758470896, 'eval_dim_64_cosine_precision@5': 0.1720243266724587, 'eval_dim_64_cosine_precision@10': 0.09417897480451778, 'eval_dim_64_cosine_recall@1': 0.606863596872285, 'eval_dim_64_cosine_recall@3': 0.7975673327541268, 'eval_dim_64_cosine_recall@5': 0.8601216333622936, 'eval_dim_64_cosine_recall@10': 0.9417897480451781, 'eval_dim_64_cosine_ndcg@10': 0.7723580363122606, 'eval_dim_64_cosine_mrr@10': 0.7185221960200228, 'eval_dim_64_cosine_map@100': 0.7223799477466899, 'eval_sequential_score': 0.7223799477466899, 'eval_runtime': 41.9214, 'eval_samples_per_second': 0.0, 'eval_steps_per_second': 0.0, 'epoch': 26.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [1:17:29<00:00, 38.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 4649.2264, 'train_samples_per_second': 14.854, 'train_steps_per_second': 0.026, 'train_loss': 0.43819571236769356, 'epoch': 26.67}\n"
     ]
    }
   ],
   "source": [
    "def prepare_training_dataset(queries, corpus, relevant_docs):\n",
    "    anchors = []\n",
    "    positives = []\n",
    "    for query_id, docs in relevant_docs.items():\n",
    "        for doc_id in docs:\n",
    "            anchors.append(queries[query_id])\n",
    "            positives.append(corpus[doc_id])\n",
    "    df = {\"anchor\": anchors, \"positive\": positives}\n",
    "\n",
    "    return Dataset.from_dict(df)\n",
    "\n",
    "\n",
    "pairs = prepare_training_dataset(queries, corpus, relevant_docs)\n",
    "\n",
    "matryoshka_dimensions = [768, 512, 256, 128, 64]  # Important: large to small\n",
    "inner_train_loss = MultipleNegativesRankingLoss(model)\n",
    "train_loss = MatryoshkaLoss(\n",
    "    model, inner_train_loss, matryoshka_dims=matryoshka_dimensions\n",
    ")\n",
    "\n",
    "# Get today's date in the desired format (e.g., YYYYMMDD)\n",
    "today_date = datetime.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Define the model name with today's date\n",
    "model_name = f\"vnuis_embedding_bge_{today_date}\"\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=f\"./Model/{model_name}\",  # output directory and hugging face model ID\n",
    "    num_train_epochs=30,  # number of epochs\n",
    "    per_device_train_batch_size=4,  # train batch size\n",
    "    gradient_accumulation_steps=128,  # for a global batch size of 512\n",
    "    per_device_eval_batch_size=4,  # evaluation batch size\n",
    "    gradient_checkpointing=True,\n",
    "    warmup_ratio=0.1,  # warmup ratio\n",
    "    learning_rate=2e-5,  # learning rate, 2e-5 is a good value\n",
    "    lr_scheduler_type=\"cosine\",  # use constant learning rate scheduler\n",
    "    optim=\"adamw_torch_fused\",  # use fused adamw optimizer\n",
    "    # tf32=False,                                  # use tf32 precision\n",
    "    bf16=True,  # use bf16 precision\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,  # MultipleNegativesRankingLoss benefits from no duplicate samples in a batch\n",
    "    eval_strategy=\"steps\",  # evaluate after each epoch\n",
    "    save_strategy=\"steps\",  # save after each epoch\n",
    "    logging_steps=10,  # log every 10 steps\n",
    "    save_steps = 10,\n",
    "    save_total_limit=2,  # save only the last 3 models\n",
    "    load_best_model_at_end=True,  # load the best model when training ends\n",
    "    metric_for_best_model=\"eval_dim_128_cosine_ndcg@10\",  # Optimizing for the best ndcg@10 score for the 128 dimension\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    args=args,  # training arguments\n",
    "    train_dataset=pairs,\n",
    "    loss=train_loss,\n",
    "    evaluator=evaluator,\n",
    ")\n",
    "# start training, the model will be automatically saved to the hub and the output directory\n",
    "trainer.train()\n",
    "\n",
    "# save the best model\n",
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 15.70 GiB of which 1.01 GiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 12.12 GiB is allocated by PyTorch, and 2.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m fine_tuned_model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\n\u001b[1;32m      2\u001b[0m     args\u001b[38;5;241m.\u001b[39moutput_dir, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfine_tuned_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(k, v)\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/sentence_transformers/evaluation/SequentialEvaluator.py:46\u001b[0m, in \u001b[0;36mSequentialEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps)\u001b[0m\n\u001b[1;32m     44\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m evaluator_idx, evaluator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluators):\n\u001b[0;32m---> 46\u001b[0m     evaluation \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(evaluation, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m     49\u001b[0m         scores\u001b[38;5;241m.\u001b[39mappend(evaluation)\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/sentence_transformers/evaluation/InformationRetrievalEvaluator.py:224\u001b[0m, in \u001b[0;36mInformationRetrievalEvaluator.__call__\u001b[0;34m(self, model, output_path, epoch, steps, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     out_txt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (truncated to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInformation Retrieval Evaluation of the model on the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_txt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 224\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# Write results to disc\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_csv:\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/sentence_transformers/evaluation/InformationRetrievalEvaluator.py:317\u001b[0m, in \u001b[0;36mInformationRetrievalEvaluator.compute_metrices\u001b[0;34m(self, model, corpus_model, corpus_embeddings)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m nullcontext() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m corpus_model\u001b[38;5;241m.\u001b[39mtruncate_sentence_embeddings(\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_dim\n\u001b[1;32m    316\u001b[0m     ):\n\u001b[0;32m--> 317\u001b[0m         sub_corpus_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mcorpus_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcorpus_start_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mcorpus_end_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     sub_corpus_embeddings \u001b[38;5;241m=\u001b[39m corpus_embeddings[corpus_start_idx:corpus_end_idx]\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:601\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    603\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:668\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    667\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:118\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    116\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    121\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:977\u001b[0m, in \u001b[0;36mXLMRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    975\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 977\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    989\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    990\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:632\u001b[0m, in \u001b[0;36mXLMRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    621\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    622\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    623\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m         output_attentions,\n\u001b[1;32m    630\u001b[0m     )\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 632\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:563\u001b[0m, in \u001b[0;36mXLMRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    560\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    561\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 563\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    568\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/transformers/pytorch_utils.py:248\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:575\u001b[0m, in \u001b[0;36mXLMRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 575\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py:474\u001b[0m, in \u001b[0;36mXLMRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    473\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 474\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/important/VNUIS-Chatbot/.venv/lib/python3.10/site-packages/transformers/activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.47 GiB. GPU 0 has a total capacity of 15.70 GiB of which 1.01 GiB is free. Including non-PyTorch memory, this process has 14.67 GiB memory in use. Of the allocated memory 12.12 GiB is allocated by PyTorch, and 2.39 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "fine_tuned_model = SentenceTransformer(\n",
    "    args.output_dir, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "# Evaluate the model\n",
    "results = evaluator(fine_tuned_model)\n",
    "\n",
    "for k, v in results.items():\n",
    "    print(k, v)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
